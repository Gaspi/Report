\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}

\usepackage[left=1.5cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{xcolor}
\usepackage[colorlinks]{hyperref}
\usepackage{graphicx}

\usepackage{includes/bussproofs}

% --- CSL part
% \usepackage{natbib}
\input{includes/pvstex}
\usepackage{includes/makebnf}

\usepackage[space]{grffile}
\usepackage{pdfpages}

\usepackage[%
backend=biber,
style=alphabetic,
backref=true,
backrefstyle=all+,
hyperref=true,
]{biblatex}

\bibliography{allbib}




% --- Partie code
\usepackage{listings}
\lstset{language=C,
        showstringspaces=false,
        basicstyle=\footnotesize\ttfamily,
        captionpos=b,
        stepnumber=1,
        keywordstyle=\bfseries\color{green!40!black},
        commentstyle=\itshape\color{purple!40!black},
        identifierstyle=\color{blue},
        stringstyle=\color{red}}

\newcommand{\cl}[1]{\texttt{#1}}

% --- Parti math. (app.)
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{remark}[theorem]{Remark}

% Mathematic abbreviations
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}

\newcommand{\mpzt}{ \texttt{ mpz\_t } }
\newcommand{\mpqt}{ \texttt{ mpq\_t } }

\newcommand{\mut}{  \textbf{ mutable } }
\newcommand{\nmut}{ \textbf{ non-mutable } }
\newcommand{\bang}{ \textbf{ mutable } }
\newcommand{\safe}{ \textbf{ safe } }
\newcommand{\dupl}{ \textbf{ duplicated } }

% evaluation context hole
\newcommand{\econt}[1]{[#1]}
% update context hole
\newcommand{\ucont}[1]{\{#1\}}


\setcounter{tocdepth}{2}

\begin{document}

\includepdf[pages={1}]{includes/frontpage/frontpage.pdf}

\newpage
\
\vspace{1.5in}
\begin{abstract}
PVS (standing for Prototype Verification System), is an Open Source project developed by CSL at SRI International and aiming to be both a semi-automated theorem prover providing formal support for conceptualization and debugging in the early stages of the design of hardware or software systems and a programming language. The evaluation of PVS expressions relies so far on a build-in PVS interpreter based on Common Lisp, called "Ground Evaluator". In order to allow the integration of PVS code as well as its fast execution for debugging and testing purposes, we describe here a translator of a subset of PVS to the language C.\\

The update of aggregate data structure, such as arrays, are frequent in functional programs and requires copying before being updated which is a significant source of space/time inefficiencies.
However the execution of updates by copying is often redundant and could be safely implemented by means of destructive, in-place updates in an imperative program.
We describe a simple method for analyzing and replacing the safe updates in an imperative program with destructive, in-place update.
This method has been implemented to optimize the PVS translator.
\end{abstract}

\vspace{1in}
\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}
I would like to thank my supervisor, Natarajan Shankar, for his help, explanations and suggestions as well as for the many enlightening discussions we had during this internship. I also thank Sam Owre for his explanations of the PVS API and Common Lisp in general, Robin Larrieu, from Polytechnique who shared an office and a lot of good ideas with me. I thank all of my teachers from  LIX who made this internship possible, with a special mention to St√©phane Graham-Lengrand and Benjamin Doerr who recommended me.
Finally, I thank all the people at the CSL, for their welcome, the interesting discussions I had with them, and for creating an exciting and inspiring environment for work. 
A special thank Lori Truitt for all the help she provided with administrative paperwork.
\end{abstract}


\newpage
\tableofcontents
\newpage

\section{Introduction}


\subsection{PVS Overview}

PVS  (Prototype Verification System) is an environment for specification and proving. The main purpose of PVS is to provide formal support for conceptualization and debugging in the early stages of the life cycle of the design of hardware or software systems. In these stages, both the requirements and designs are expressed in abstract terms that are not necessarily executable. The best way to analyze such an abstract specification is by attempting proofs of desirable consequences of the specification. Subtle errors revealed by trying to prove the properties are costly to detect and correct at later stages of the design life cycle. \\

The specification language of PVS is built on higher-order logic (functions can be treated like primitive types: functions can take functions as arguments and return them as values, quantification can be applied to function variables. Specifications can be constructed using definitions and axioms





\subsection{Why translate PVS ?}

Translating a specification language into an 

\subsubsection*{The HACMS Project}

The DARPA-funded project High Assurance Cyber-Military System (HACMS) aims to produce systems and software with proved reliability and security. It uses the abstraction of nodes and topics to describe the different components and communication
channels. A PVS model of these nodes and topics allows to prove security properties. However the project requires an implementation and integration of the proven algorithms into the system. For that purpose, a translator PVS to C would be very helpful since most of the ROS systems use the C language.

\subsubsection*{Other translators}

Translating PVS was already done for different purposes.
\begin{itemize}
\item PVS come with a native PVS to Common Lisp translator. This is used to run PVS programs for testing and debugging purposes. Since PVS's API relies heavily on the Common Lisp language, it is very easy to run PVS code within Emacs. The "Ground Evaluator" uses the generated Common Lisp code to evaluate PVS expressions. It provides a more user-friendly interface for the PVS translator by being integrated into Emacs and translating simple Common Lisp expression back to PVS.
\item PVS expressions can also be translated to Yices's specification language syntax. Yices is an efficient SMT solver developed at SRI by Bruno Dutertre. This translation is a way to "plug" the Yices solver into PVS, allowing automated proof of theorems and TCCs.
\item PVS was translated to the Clean language.
\item Lately PVS was also translated to the SMT-LIB language (work in progress) for standardization purposes. This would allow every SMT solver able to process SMT-LIB standard inputs such as Yices 2, to be plugged into PVS for further proof automation.
\end{itemize}


\newpage
\section{Translating PVS}

A translator is a program taking the source code of program $P$ written in the programming language $\mathcal{L}_A$ as an entry and generating the code of an other program $Q$ in the target language $\mathcal{L}_B$ as an output. In our case, $\mathcal{L}_A$ is a subset of PVS and $\mathcal{L}_B$ is the language C. It is expected from a translator to:
\begin{itemize}
\item Never fail if the entry is the code of a valid program in the input language, $\mathcal{L}_A$. However the translator might declare being only able to translate a fragment of the language and restrict its input language. In our case, we expect input programs to be written using the syntax in Figure~\ref{fig:PVSsyntax}, to be parsed and typechecked using PVS without error and finally, we expect that TCCs generated by PVS can be proven.
\item Generate a valid program in the target language $\mathcal{L}_B$.
\item For all entry $x$, $P(x)$ and $Q(x)$ return the same result (correctness).
\end{itemize}


\subsection{Translator's architecture}

The translation from PVS \cite{PVS:manuals} to C follows these main steps:
\begin{itemize}
\item Typechecking: The PVS typechecker \cite{PVS:userguide} perform a type analysis on the PVS code to associate a PVS type to each expression. This might generates some proof obligations (TCC). The user of the translator has to make sure that the PVS code can be correctly typechecked and that all TCC can be proven.

\item Lexical and syntactic analysis: The PVS parser transforms PVS \cite{PVS:language} code into a CLOS internal representation. \\

In Figure~\ref{fig:PVSsyntax}, we describe the syntax of the subset of PVS we are currently able to translate to C.
In Figure~\ref{fig:PVS-CLOS}, we describe the Common Lisp Object System architecture used by PVS to represent them in Common Lisp. Some classes and some slots in the classes are voluntarily omitted. For a full description of PVS parser representation, refer to \cite{PVS:api}.

\item Translation: The translator flattens all PVS definitions to generates a program in an intermediate language which heavily relies on the use of intermediate variables to store the values of every expression. Besides, this form allows a simpler static analysis. The translation is briefly described in subsection~\ref{subsec:pvssyntax}. The syntax of this language is described Figure~\ref{fig:aux-syntax}.

\item Static analysis: The intermediate language is analyzed and stripped from some of its unnecessary copies and non destructive updates using flow analysis. This analysis inspired from Shankar \cite{shankar02} and Pavol Cerny's \cite{pavol} previous analysis of PVS is described with more detail in Section~\ref{sec:StaticAnal}.

\item Optimizations: Several simple analysis are performed to determine, for instance, where to declare and free variables as well as the most adapted C types to use. The output is a more complete and closer to C version of the intermediate language. The type translation is described in the subsection~\ref{subsec:pvstypes}. The code generated from that step can be described by the syntax in Figure~\ref{fig:Csyntax}. 

\item Code generation: C code is generated (.c and .h files) and can be compiled using gcc and executed when linked with the garbage collector and the GMP library. The C syntax is described in \cite{huss2004c} and the GMP library reference can be found at \href{https://gmplib.org/manual/}{https://gmplib.org/manual/}.
\end{itemize}



\subsection{Translating PVS type}
\label{subsec:pvstypes}

\subsubsection{PVS type system}
A PVS theory needs to be typechecked using the emacs interface \cl{M-x typecheck} or calling the Lisp function \cl{(tc name-theory)}. This runs the PVS parser on the code and generates CLOS objects to represent it. Then, the PVS typechecker is run on this internal representation of the theory and tries to give a type to all expressions generating TCC when needed.\\

The (simplified) syntax for PVS types is described in Figure~\ref{fig:PVS-types}. PVS allow a base types such as \cl{boolean}s or \cl{number}s. Then more complex types can be defined such as sets, tuples, datatypes or functions with range and values over other types. Types can also be restricted into subtypes using predicates. For example, \cl{integer}s are defined as a subtype of \cl{rational}s with the predicate \cl{integer\_pred}. This way, when an expression is passed to a function ranging over integers, the typechecker generates the TCC "argument must verify the predicate \cl{integer\_pred}". That TCC must then be proven (it is often proven automatically for such simple TCCs). \\

The Figure~\ref{fig:PVS-CLOS-types} describes how PVS type system is represented in CLOS. 


\subsubsection{C types}
The C language \cite{huss2004c} has a few base types to represent bounded integers (\cl{int}, \cl{long}, etc). It allows to define enumerated types, structures containing several fields with different types. The variables with a pointer type have a memory address as a value. They can be used to reference arrays dynamically allocated in the heap.

To represent big integers or rationals, we use the GMP library which introduces a few other types.

\begin{lstlisting}[caption=C types]
// integer and floating point types
[unsigned] char, int, long, double
type*         //arrays
char*         // strings
struct types  // structures with fields
enum types    // enumerated types
mpz_t, mpq_t  // GMP library
short int, float, union, size_t // etc...
\end{lstlisting}


\subsubsection{Translation rules}
The translation of PVS types requires a type analysis to decide on the type of a PVS expression.

For instance the translation of the PVS \cl{int} type can be done using the \cl{int}, \cl{unsigned long} or \cl{mpz\_t} C types. In that case, we need to study the range of the expression to decide which types are best to represent it. Then we take the context in which the expression appears to decide. For instance when a variable \cl{x} is typed with a subtype that bounds the range of the values \cl{x} can take, we can safely represent it with a C bounded type.
\begin{lstlisting}
incr(x:below(10)):int = x+1
int incr(int x) { return x+1; }
\end{lstlisting}
In that case, we not only decide to represent \cl{x} with an integer but also the expressions \cl{1} and \cl{x+1} as well as the return value of \cl{incr}. This requires an range analysis to realize that $\cl{1} \in [1;1]$ and $\cl{x+1} \in [1;10]$ can both be represented by the \cl{int} type.\\

When such optimizations are impossible we have to rely on bigger base types or use the GMP types which can generate a much less readable code (see Section~\ref{sec:Concl}, Figure~\ref{fig:exGMP}) and often requires a few conversions. \\

We decide represent functions ranging over integer bounded type with index starting at 0 with arrays and other with closures. It is the responsibility of the user who needs an efficient representation with C arrays to use such types.\\

We describe here a few translation rules
\begin{figure}[!ht]
\begin{tabular}{|l|l|}
\hline
\cl{subrange(a, b)} &
\begin{lstlisting}
int            // if small enough
unsigned long  // if too big or needed for function call
mpz_t          // else
\end{lstlisting} \\ \hline
\cl{int} &
\begin{lstlisting}
mpz_t
\end{lstlisting} \\ \hline
\cl{rat} &
\begin{lstlisting}
mpq_t
\end{lstlisting} \\ \hline
\cl{[below(a) -> Type]} &
\begin{lstlisting}
(Ctype)*
\end{lstlisting} \\ \hline
\cl{T : TYPE = [\# $x_i$ : $t_i$ \#]}  &
\begin{lstlisting}
struct CT {
   ...
   Ct_i x_i;
   ...
}; // These types must be declared
\end{lstlisting} \\ \hline
\cl{[Range -> Domain]} & C closure parameterized by the \cl{Domain} return type.\\ \hline
\end{tabular}
\caption{Translation rules for PVS types}
\end{figure}



We can only translate a subset of all PVS types.
What's missing ?












\subsection{Translating PVS syntax}
\label{subsec:pvssyntax}


We can only translate a subset of PVS syntax.
What's missing ?


Typically, an expression $e$ is translated into a tuple of four elements $(t,e,i,d)$, where $t$ represents a C type used to describe the expression, $e$ is a simple expression, $i$ is a list of instructions to be executed prior to using $e$, the initialization of the expression. Finally $d$ is a list of instructions to be executed when $n$ isn't needed anymore, the destruction of $e$.





\subsubsection{A few translation rules}

We first define a function $T$ to translate an expression $e$.
$$ T(e) = ( \ T^t(e) \ , \ T^n(e) \ , \ T^i(e) \ , \ T^d(e) \ ) $$

\begin{figure}[!ht]
\begin{eqnarray*}
T(\cl{2}) &= (& \cl{int}, "2", [], []) \\
T(\cl{4294967296}) &= (& \cl{mpz\_t}, \ ? \ , \\
&& [ \cl{mpz\_init(?);} \ | \\
&& \ \cl{mpz\_set\_str(?, "4294967296");} ],\\
&& [ \cl{mpz\_clear(?);} ]) \\
T(\cl{lambda(x:below(10)):x}) &= (& \cl{int*}, \ ? \ , \\
&& [ \cl{? = malloc(10 * sizeof(int));} \ | \\
&& \ \cl{int i;} | \\
&& \ \cl{for(i = 0; i < 10; i++) }\\
&& \ \ \ \cl{?[i] = i;}  ]\\
&& [ \cl{free(?);} ])
\end{eqnarray*}
\caption{Translation examples: number expressions}
\end{figure}

It may occur that $T^n(e) = ?$. In that case, the symbol $?$ appearing in $T^i(e)$ and $T^d(e)$ needs to be replaced by a proper variable name.\\

We then define two other operators:
\begin{itemize}
\item $R$ wich take an expression and a type and may add an extra conversion in the instructions to make sure its result has the expected type. Also the result of this function has a proper name.
\item $S$ which take an expression, a type and a name. It makes sure that the given variable (type + name) is set to a value representing the expression.
\end{itemize}






\begin{lstlisting}
number-expr "2"
(C-int, "2", [], [])

number-expr "12315468453213"
(C-mpz, nil,
        [mpz_t ~a; | mpz_t_init("12315468453213"); ],
        [mpz_clear ~a;])

application "f(e1, e2)"
(C-mpz, nil,
       [ instr(e1) | instr(e2)
                   | mpz(~a); | f(~a, e1, e2) ]
       [mpz_clear(~a);]
\end{lstlisting}





\subsection{Optimization of the intermediate language}

We perform two main analysis on the intermediate language.
\begin{itemize}
\item The first one consists in replacing non destructive updates with destructive updates as often as possible. The algorithm is described in Section~\ref{sec:UpdateExpr} and the analysis itself is described in Section~\ref{sec:StaticAnal}.
\item 
\end{itemize}



\section{Update expressions}
\label{sec:UpdateExpr}

It is a complicated problem to decide while compiling a functional language whether an update expression should be translated into a destructive or non destructive update in the target imperative language.\\

PVS update expressions are represented in CLOS as \texttt{update-expr} objects
$$ E := \cl{ $T$ with [ ($e1$) := $e2$ ] } $$
where $T$ is an expression typed as a function and therefore might be represented in C as an array (if domain type is \cl{below($n$)}.
We want to know if we can update $T$ in place to obtain a C object representing $E$ or if we have to make a copy of $T$ and update the copy.\\

We discuss here a few solutions to this problem and describe how they are or could have been implemented in the translator.

\subsection{Pointer counting}

Several systems rely on a reference counting garbage collectors. This family of garbage collectors has many advantages \cite{jonesgarbage}. Along with its simplicity and the instantaneity of garbage identification, the one we are interested in is the possibility to determine when a local variable is the only pointer to a complex data structure. In that case, at the cost of a simple test, we can avoid copies and perform destructive updates. \\

The idea is to keep track of the number of pointers pointing to an array or a struct. We can detect, by checking the pointer counter, if an array is referenced in several portions of the code (nested reference in other data structure, local variable in calling function, ...) and then perform all updates non destructively to avoid inconsistency.\\

We implement a very simple "Reference Counting Garbage Collector" as described in \cite{jonesgarbage} and integrate it to the C code generated.\\

The GC consists in a hashtable of pointer counters that we maintain during the execution of the code. Each pointer to data allocated on the heap is a key in the hashtable to which we associate an int counter as value. We then make sure that all memory allocations in the code make a call to the GC to "declare" the new memory. The GC we implemented is described Figure~\ref{fig:GC.h}.

\begin{tabular}{|p{5cm}|p{11cm}|}
\hline
\begin{lstlisting}
T* a = malloc(
     10 * sizeof(int));
\end{lstlisting} & \begin{lstlisting}
T* a = (T*) GC_malloc(10 * sizeof(int));
\end{lstlisting}
All memory allocation are handled by the GC to make sure every new reference on the heap is in the reference table and has a pointer counter associated to it.
\\ \hline
\begin{lstlisting}
free(a);
\end{lstlisting} & \begin{lstlisting}
GC_free(a);
\end{lstlisting}
This will decrement the reference counter on \cl{a} and might free it if this counter is now 0. \\ \hline
\begin{lstlisting}
T* a = b;
\end{lstlisting} & \begin{lstlisting}
T* a = (T*) GC( b );
\end{lstlisting}
The reference count on \cl{b} is incremented to represent that the local variable \cl{a} now also points to the structure \cl{b} points to.\\ \hline
\begin{lstlisting}
t[0] = b;
\end{lstlisting} & \begin{lstlisting}
GC_free( t[0] );
t[0] = (T*) GC( b );
\end{lstlisting}
This time, we also make sure the reference counter of \cl{t[0]} is decremented and \cl{t[0]} has a chance to be freed if nothing else points to it.\\ \hline
\end{tabular}

\begin{figure}
\begin{lstlisting}
struct entry_s {
   void*  pointer;
   int    counter;
   struct entry_s *tl;
};
typedef struct entry_s* entry;

struct hashtable_s {
   int    size;
   entry* table;	
}; 
typedef struct hashtable_s* hashtable;

hashtable ht_create  ( int size );
int       ht_hashfunc( hashtable hashtable, void* pointer );
entry     ht_newentry( void* pointer );

hashtable GC_hashtable;
void      GC_start();
void      GC_quit();
entry     GC_get_entry( void* pointer );
void      GC_add_entry( entry e);
void      GC_new( void* pointer );
void*     GC( void* pointer );
int       GC_count( void* pointer );
void*     GC_malloc( int length, int size );
int       GC_free(void* pointer);
\end{lstlisting}
\caption{Garbage collector C header file: GC.h}
\label{fig:GC.h}
\end{figure}



\subsubsection{How to use it}

The garbage collector must be used for every manipulation of pointers to memory which was dynamically allocated on the heap. This occurs typically when representing PVS arrays or data structure. \\

When \cl{A} points to an array (or \cl{struct}) we want to update destructively, we first have to check if the pointer counter on \cl{A} is 1. If so, we can update in place because only the local variable \cl{A} points to the array.\\

However, we need to be careful.
$$ \cl{g(A:Array) : int = f(A, A WITH [(0) := 3] )}$$
should not be translated to
\begin{lstlisting}
g(int* A) {
  A[0] = 3;
  return f(A, A);
}
\end{lstlisting}
for (at least) two reasons:
\begin{itemize}
\item The variable \cl{A} is updated destructively but it is later used as a reference to the previous value of the array.
\item \cl{f} is given twice a pointer to the same data structure. Its reference counter should be incremented.
\end{itemize}

Below are a few rules a good use of the GC should follow (see Figure~\ref{fig:exampleGC}).
\begin{enumerate}
\item All dynamically allocated memory on the stack should be done using the GC.
\item All function is responsible for freeing all its arguments. Indeed, the local variable implicitly created to represent the argument is itself a pointer to the structure.
\item All argument passed to a function must have its counter incremented via the GC.
\end{enumerate}
However a few optimizations are possible. For instance if a variable has its counter incremented before being passed to a function and is then freed right after, then it can be directly passed and rely on the function call to free it.
\begin{figure}[!ht]
\begin{lstlisting}
void main() {
   GC_start();
   
   int* A = GC_malloc(10, sizeof(int) );  // Pointer counter of A = 1
   int i;
   for(i = 0; i < 10; i++)  // Initialisation of A
      A[i] = i;             // Here A = lambda(x):x
   int* B = g( GC(A) );     // We need A further, we make sure that g knows
   int* C = A;              // main still has a pointer to A
   printf("Pointers to C = %d", GC_count(C) ); // equal to 2
   GC_free(B); // Frees B
   GC_free(C); // Only decrement the counter of C
   GC_free(A); // Frees A (and C)
   GC_quit();
}

g(int* A) {
  int* arg1 = GC(A);           // A and arg1 now both point to the array
  int* arg2;
  if (GC(A) == 1)             // This is false
     arg2 = GC( A );
  else {                      // The update must be done non destructively
     arg2 = GC_malloc( 10, sizeof(int) );
     int i;
     for(i =0; i < 10; i++)
         arg2[i] = A[i];
  }  
  arg2[0] = 3;
  GC_free(A);                 // A is never used afterwards, we free it here
                              //(this requires an analysis of the C code)
  int* result = f(arg1, arg2);// A function is responsible for freeing its arguments
                              // (this is why we don't free arg1 and arg2)
  return result;
}
\end{lstlisting}
\caption{Example of the use of the GC}
\label{fig:exampleGC}
\end{figure}

But again, we are lucky here that \cl{A} is the first argument of \cl{f}. If the updated \cl{A} were the first arguments, the update would have been done destructively.\\

This is why the GC alone is not enough. We need an analysis of the C code to determine whether a variable is going to be used later in the code or not (\safe occurrence, cf \hyperref[Canalysis]{\ref*{Canalysis} Analysis of the intermediate language}).


\subsubsection{Pros and cons}

The use of a garbage collector integrated in the C code seems like a good idea when translating a functional language to C. Using a pointer counting GC allows to dynamically allocate memory on the heap and pass or return such dynamically allocated object without worrying about where and when they are going to be freed.\\

We however need an analysis of the C code for several reasons:
\begin{itemize}
\item To \cl{GC\_free} variable as soon as they are not needed anymore. Otherwise copies that could be avoided are performed because an other (useless) pointer still points to the structure we're interested in.
\begin{lstlisting}
int* B = GC( A );
update(B, 0, 1); // Can't be done destructively because A also points to
GC_free(A);      // the same data as B
f( GC(B) );      // f is given a variable with a reference counter of 2.
GC_free( B );    // It might not be able to perform some update destructively
\end{lstlisting}
Should be
\begin{lstlisting}
int* B = A;
update(B, 0, 1);  // Can now be done destructively
f( B );           // f is given a variable with a reference counter of 1.
\end{lstlisting}
\item Every update require now tests and calls to hashtable functions. This is a small cost compared to the copying it may allow to avoid but no so small compared to a single in place update that could be decided by a code analysis.
\item Besides, the code gets much bigger since every update or copy requires the code to both destructive and non destructive operation and the if statement to decide which one to use. For instance, passing arguments to a function adds quite some code
\begin{center}
\begin{tabular}{|c||c|}
\hline
GC use & Static analysis optimization \\ \hline
\begin{lstlisting}
int* f(int* arg) {
   int* result;
   if ( GC_count(arg) == 1)
      result = GC( arg );
   else {
      result = GC_malloc(10, sizeof(int));
      int i;
      for(i = 0; i < 10; i++)
         result[i] = GC( arg[i] );
   }
   GC_free(arg);
   result[0] = 3;
   return result;
}
\end{lstlisting}
&
\begin{lstlisting}
int* f(int* arg) {
   arg[0] = 3;
   return arg;
}
\end{lstlisting} \\ \hline
\end{tabular}
\end{center}

\end{itemize}




\subsection{Using a more adapted data structure}

The Lisp code generated by PVS and used for example by the ground evaluator to compute PVS expressions represents PVS arrays with a more complex data structure than a simple array. It basically consists in an array and a replacement list. Every time an update on \cl{(A, l)} is performed, the result is a pointer to the same array \cl{A} and a replacement list with an extra term.
\begin{eqnarray}
\cl{T} &\Longrightarrow& \cl{(A, l)} \\
\cl{T[(0) := 0]}&\Longrightarrow& \cl{(A, (0:=0) :: l)}
\end{eqnarray}
When the replacement list becomes too long (longer than $\tau(n)$), we create a new array \cl{A'} by applying the replacement terms to a copy of \cl{A} and we return \cl{(A', nil)}. The hope is that by the time we need to perform this copy, nothing else points to the old array so that it is garbage collected immediately. The trade off can be summarized with:

\begin{center}
\begin{tabular}{|l|l|p{10cm}|}
\hline
 & Copied array & New data structure \\ \hline
Update time & $O(n)$ & $O(n)$ (if copying is needed) but most of the time $O(1)$.  \\ \hline
Update space & $O(n)$ & $O(n)$ (if copying is needed and the old array is not garbage collected) but most of the time $O(1)$. \\ \hline
Access time & $O(1)$ & $O(\tau(n))$ since we need to read the replacement list. \\ \hline
\end{tabular}
\end{center}

We could represent C data structure with a similar C structure. For example :
\begin{center}
\begin{tabular}{ccc}
\begin{lstlisting}
struct array_int {
   int *data;
   r_int_list* replacement_list;
};
\end{lstlisting}
&  \hspace{2cm} &
\begin{lstlisting}
struct r_int_list {
   int key;
   int value;
   r_list* tl;
};
\end{lstlisting}
\end{tabular}
\end{center}

We have the following issues:
\begin{itemize}
\item This adds some extra code both to implement the new data structures and algorithms and to use them.
\item This adds some extra run time for reading accesses which require reading the whole replacement list.
\item This relies a lot on the GC.
\end{itemize}


\subsection{Flow analysis on the PVS code}

An other optimization would be to perform an analysis on the PVS expressions. Shankar \cite{shankar02} and later Pavol \cite{pavol} suggest several analysis based on flow analysis that allow to replace PVS non destructive updates with destructive updates.\\

These analysis require the definition of two versions of each function. A safe version that can always be called and never  performs any destructive update and an other "destructive" version that can only be called under certain conditions on the arguments. However thanks to these conditions, the body of that destructive version is allowed to perform safe destructive update and may call destructive versions of functions.\\

We didn't implement these analysis into the translator but they inspired the static analysis on the intermediate language described next.


\subsection{Analysis of the intermediate language}
\label{Canalysis}

One of the solutions we decided to implement to solve the update problem  consists in an analysis on the intermediate language before the optimization and generation of the actual output C code.\\

We also use two different versions of a PVS function called $f$ and $f^d$. Our analysis differs from Shankar and Pavol's preivous work in (at least) the following:
\begin{itemize}
\item The non destructive version of a function is also optimized and might have some destructive updates or function calls.
\item The destructive function does not have all its function call destructive.
\end{itemize}

The analysis is explained in details in Section~\ref{sec:StaticAnal}. The analysis we implemented basically relies on over approximations of the sets of critical and free variables in a context.

\subsubsection*{The flags}

We define three flags:
\begin{itemize}
\item \bang means that the variable is the only pointer to the structure or array it points to. For instance if we have \cl{f(A:Arr):Arr = A WITH [(0) := 0]} then when \cl{f} is called in
$$ \cl{let A = lambda(x:int):x in let B = f(A) in B(0)} $$
we know that \cl{f} can update \cl{A} in place. We call the following version of \cl{f}.
\begin{lstlisting}
int* f(int* A) {
  A[0] = 0;
  return A;
}
\end{lstlisting}

\item \safe means that an occurrence of a variable is the last occurrence of that variable in the code. We need this flag to avoid updating destructively variables that appears later in the code. In the previous example, if we encounter
$$ \cl{let A = lambda(x:int):x in let B = f(A) in B(0) + A(0) }$$
we know we can't update \cl{A} destructively and we call instead a non-destructive version of \cl{f}:
\begin{lstlisting}
int* f(int* A) {
  int* res = malloc(...);
  for( i ...) res[i] = A[i];
  res[0] = 0;
  return res;
}
\end{lstlisting}

\item \dupl means that this expression may find itself nested in the result of the current function. For instance the identity function, \cl{id(A:Arr):Arr = A}, has its argument flagged \dupl. Therefore when \cl{id} is called we know that the result contains a pointer to its argument.
\begin{lstlisting}
...
int* A = malloc(...);
[ init A somehow ]
int* B = id(A);
\\ From now on B and A point to the same array
\\ For instance, A should probably not be modified in place
...
\end{lstlisting}
\end{itemize}

To connect with the analysis Section~\ref{sec:StaticAnal}, we could say that
\begin{itemize}
\item If $f(f_i) := U\ucont{\cl{set(}x\cl{, }a\cl{); }e}$, the variable $x$ is flagged \bang when all $Ov(a)$ are flagged \bang as well and are neither live in $U$ nor free in $e$.
\item If $f_i$ is flagged \bang, then $f_i \in BA(f)$. This is why we ensure no arguments in non destructive versions of functions are flagged \bang.
\item A occurrence of a variable $x$ is flagged \safe when this variable is not live in the context of that occurrence.
\item An expression $a$ is flagged \dupl when $Av(a) \subset Av(e)$. We are only interested in the arguments of $f$ that are flagged \dupl though.
\end{itemize}

We want to ensure the following properties on the flags
\begin{itemize}
\item Only function declarations and variables with type struct or array can be flagged \bang.
\item Only a single occurrence of a variable may be flagged \safe.
\item Only expressions and arguments can be flagged \dupl.
\item The last and only the last occurrence of a variable is flagged \safe.
\item Arguments of a non destructive function are never flagged \bang.
\item A function is flagged \bang iif its return variable is flagged \bang.
\item A variable may be flagged bang if it is created with a \cl{copy}, \cl{init\_array}, \cl{init\_record} or is the result of a call to a function flagged \bang.\\
It may not be flagged \bang if it is the result of a call to a function not flagged \bang.
\item A call to a destructive function \cl{f\_d( $a_i$, $b_j$, $c_k$ )} (where $a_i$ are flagged \bang and $b_j$ are flagged \dupl and $c_k$ are not flagged) may only occurs if the following conditions on the arguments passed $( A_i, B_j, C_k )$ are met:
\begin{itemize}
\item All $A_i$ are either calls to functions flagged \bang or variables flagged \bang and \safe.
\item All $B_j$ are either calls to functions or variables flagged \safe or not flagged \bang.
\item If the function call is flagged \dupl, then all $B_j$ are also flagged \dupl.
\end{itemize}
\item If a variable is once flagged \dupl, then if it is an argument, this argument is also flagged \dupl.
\end{itemize}



\subsubsection{Algorithm}

Each PVS function is translated into two different C functions:
\begin{itemize}
\item A "cautious" non destructive version whose arguments are never \bang and therefore never modifies the arguments in place, always making copies when necessary. This doesn't mean this function can't make destructive update. For instance locally created arrays (using \cl{init\_array}) will be flagged \bang and might be destructively updated, should the conditions be met.
\item A destructive version which requires as many arguments as possible to be \bang and tries to do destructive updates as often as possible. This function only requires \bang arguments if it uses it destructively though.
\end{itemize}


\begin{figure}
\begin{lstlisting}
f(int* A, int* B) {         // A and B are both flagged duplicated
   if (A[0] == 0) {
      return B;
   } else {
      int* arg1 = copy(B);  // arg1 is flagged mutable and duplicated
      arg1[0] = arg1[0] - 1;
      f(arg1, A); // Both these occurrences of arg1 and A are flagged safe
   }
}

f_d(int* A, int* B) {  // A and B are both flagged mutable and duplicated
   if (A[0] == 0) {
      return B;
   } else {
      int* arg1 = B;    // No need to copy since B is mutable
                        // and never occurs afterwards
      arg1[0] = arg1[0] - 1;
      f_d(arg1, A);     // we can call f_d since the requirements are met:
   }                    //    both arg1 and A are flagged mutable
}
\end{lstlisting}
\caption{Example of the two different versions of a C function generated (stripped from GC instructions)}
\end{figure}




\begin{figure}
\begin{itemize}
\item Create the two versions of a function
\item Flag all arguments \bang in destructive version
\item Perform several passes and move flags to make sure the properties Figure~\ref{fig:properties} are verified.
\item Modify the code if the flags allow it according to the rules defined in the Annex~\ref{Rules}.
\item Redo the two previous steps until stabilization.
\end{itemize}
\caption{Algorithm}
\end{figure}





In destructive versions of all functions :
Flag all array arguments to "mutable".
Then for each of these arguments :
  - If it never occurs destructively, then remove flag
          (function just read the arg)
  - If it occurs destructively, it can never occur at all AFTER.
  -> Need to define the order of evaluation of expression
      (easy rules on simple expressions)
  -> Need to be able to detect occurrences of a name-expr
  -> Otherwise, unflag the arg

A variable $V$ of type array is created in these cases:
\begin{itemize}
\item \cl{$V$ = $\lambda$x.e(x)} : $V$ has bang type
\item \cl{update($V$, $T$, key, value)} : $V$ has bang type because this is basically a copy and a destructive update.
\item \cl{f($V$,...) = ...} : type of $V$ depends on \cl{f}.
\end{itemize}
In these case, it has always bang type.\\
Or it can be set to an other referenced object.
\begin{itemize}
\item \cl{$V$ = $T$} $\rightarrow$ $V$ (should have bang type iff $T$ has !type too and never occurs afterwards). Happens in 
\item \cl{$V$ = $T$[i]} $\rightarrow$ depends on the target type of $T$.
\item \cl{$V$ = $T$.field} $\rightarrow$ depends on the type of the field.
\end{itemize}
At first all updates are non destructive.

First pass : All array variables (actuals and local variables) found in the code are flagged. Local variables are flagged according to the previous rules and actuals are flagged \textbf{mutable} in destructive version and \textbf{not mutable} in non-destructive versions. In functions returning an array (or record type), the variable result is also flagged.\\

Other passes :
Reading the code backwards, for every occurrence $T$ of a variable flagged \textbf{mutable}:
\begin{itemize}
\item If it is found in a \cl{$V$ = $T$} instruction, then we give the bang type to $V$ and remove bang type from $T$ so that previous occurrences of $T$ won't assume the uniqueness of the reference. This adds a new variable to the set of bang variables, hence the need to make several passes.
\item If it is used in a \cl{$V$ = copy($T$)} instruction, then we replace it with a \cl{$V$ = $T$} instruction and do as previous.
\item If it is found in an \cl{update($V$, $T$, i, e}, then turn that into \cl{$V$ = $T$; destr\_update($V$, i, e) }.
\item If it is a function call 
\item If we reach the declaration of a variable that is marked \textbf{mutable}, this means this variable is never read. In that case, we actually don't need it (unflag it I guess...).
\end{itemize}

At the end, when we have reached the transitive closure of this definition, if we reach the beginning of the function and some arguments are still bang, this means their bangness is never used, put the flag on that argument to \cl{non mutable} and remove the instructions freeing that variable (reminder : mutable arguments of a functions are freed inside the function or are used in a mutable way and appear somewhere in the result (trapped in closures) or are freed in other function calls.



\subsubsection{Algorithm}




All variables have three flags: $M$ (mutable), $D$ (duplicated) and $T$ (treated).

Init:\\
All arguments of a destructive function are flagged \cl{($M$ = true, $D$ = false, $T$ = true)}.\\
All arguments of a non destructive function are flagged \cl{($M$ = false, $D$ = false, $T$ = true)}.\\
All other variables are flagged \cl{($M$ = false, $D$ = false, $T$ = false)}.\\

Rules:\\
When $M$ is changed, $T$ is set to \cl{true}.\\
When $T$ is \cl{true}, the flag $M$ can only be set to \cl{false}.
This prevent infinite change of the flag $M$.\\
The flag $D$ can only be set to \cl{true}.\\



Initialization:\\


We initialize a set $M$ of mutable variables to all array arguments of a function $f$.
We also initialize a set $F$ of variables to free to $M$ since $f$ has the resposnability to free all variables flagged as mutable arguments.\\

We read the code backwards.\\
$T_i$ refer to variables that are in the set $M$.\\
$S_i$ refer to variables that are not in the set $M$.

\begin{tabular}{|p{60mm}|p{90mm}|}
\hline
\cl{$S$ = $T$} & $M \leftarrow M \cup \{ S \} - \{T\}$ \newline $F \leftarrow F \cup \{ S \} - \{T\}$  \\ \hline
\cl{$S$ = update($S_2$, key, value}) & $M \leftarrow M \cup \{ S \}$ \newline $F \leftarrow F \cup \{ S \}$ \\ \hline
\cl{$S$ = update($T$, key, value}) & $M \leftarrow M \cup \{ S \}  - \{T\}$ \newline $F \leftarrow F \cup \{ S \}$ \\ \hline

\cl{$S$ = g($T_i$, $S_i$}) & If the arguments of \cl{g} don't allow \cl{g} to be called destructively: \newline $M \leftarrow M - \{T_i \}$ \newline $M \leftarrow M \cup \{ S \}$ if return type of \cl{g} is \mut \newline $F \leftarrow F \cup \{ S\}$ \\ \hline

\cl{$S$ = g($T_i$, $S_i$}) & Otherwise: \newline \cl{$\rightarrow S$ = g\_d($T_i$, $S_i$} \newline $M \leftarrow M \cup \{ S \}  - \{T\}$ \newline $F \leftarrow F \cup \{ S \}$ \\ \hline

\cl{$S$ = $S_2$[i]} & $M \leftarrow M \cup \{ S \}  - \{T\}$ \newline $F \leftarrow F \cup \{ S \}$ \\ \hline


\end{tabular}




All arguments of the function are flagged \mut 




What is a destructive occurrence :
$$ E :=  \cl{f(  t with [ e1 := e2 ] , t(0) )} $$
order of eval :
e1 and e2  (t can occur non destr)
t          ( expression of an update : destr)
t(0)       ( occurrence of t (even non destr))

\cl{f(x:Arr):int = g( h(t), t)}  is destructively translated to \\
\begin{lstlisting}[numbers=left,caption=Example]
int f_d(int* t) {   // t has type ! since this is destructive f
  int* arg1 = h(t); // h can't be called destructively because
                    // even though t is !, it appears later (line 4)
  int* arg2 = t;    // t is ! and never appears later => arg2 is !
  return g( arg1, arg2); // arg2 is ! but g can only be called
}                        // destructively if arg1 is
\end{lstlisting}

if g has type \cl{[Array! -> ?]} then t can't be destructive\\

if g has type \cl{[Array -> ?]} then t can be destructive

First algorithm:


Need multiple passes as the flags disappear


\begin{figure}[!ht]
\begin{tabular}{|p{50mm}|p{62mm}|p{45mm}|}
\hline
\cl{update(A, key, value)} & \cl{A[key] = value;} & \cl{A} must be \mut \\ \hline
\cl{set(A, $expr$)} & \cl{A = $expr$;} \\ \hline
\cl{declare(A, $expr(i)$)} & \begin{lstlisting}
A = malloc(l * sizeof(T) );
int i;
for(i = 0; i < l; i++)
   A[i] = i + 1;
\end{lstlisting} & \\ \hline
\cl{copy(A, B)} & \begin{lstlisting}
A = malloc(l * sizeof(T) );
int i;
for(i = 0; i < l; i++)
   A[i] = B[i];
\end{lstlisting} & \\ \hline
\cl{init(A)} & \cl{int* A;} & \\ \hline
\cl{free(A)} & \cl{free(A);} & \\ \hline
\cl{base(str, (A, B, ...))} & \cl{int aux = A[0] + B[1];} & \cl{A} and \cl{B} are only read. \\ \hline
\cl{return} & \cl{return result;} & \\ \hline
\end{tabular}
\caption{C instructions}
\end{figure}



\begin{figure}[!ht]
\begin{tabular}{|p{50mm}|p{50mm}|p{50mm}|}
\hline
\cl{value($cste$)} & \cl{42} & \\ \hline
\cl{variable($type$, $name$)} & \cl{name} & \\ \hline
\cl{call(f, $exprs$)} & \cl{f( $expr_1$, $...$, $expr_n$ )} & \\ \hline
\end{tabular}
\caption{C expressions}
\end{figure}




\subsection{Combination of solutions}

We use the C code analysis to write some updates as destructive. However a few updates remain non destructive. For example:\\

If a function is called but requires its two argument to be \mut  and only the first is \mut. Then the non-destructive version is called and the first argument gets copied even though it was \mut.\\

If we perform an update on \cl{$T$[i]}, our analysis doesn't tell if \cl{$T$[i]} is \mut or \nmut.\\

To prevent that, we also perform a GC check. An update is actually a test wether an object is \mut or not and the appropriate update.






\newpage
\section{Static analysis of the intermediate language}
\label{sec:StaticAnal}

We describe here the static analysis of the intermediate language (which syntax is defined in Figure~\ref{fig:aux-syntax}) implemented in the translator.

\begin{figure}[!ht]
\input{includes/aux-expr}
\caption{Syntax of the intermediate language}
\end{figure}

We assume a few properties on valid programs:
\begin{enumerate}
\item The \cl{set} instruction is a declaration and an assignment of a variable to a value at the same time. If an expression contains two \cl{set} of the same variable, the second \cl{set} will override the first definition. We assume then that a variable is never \cl{set} twice in the same expression.
\item The only free variables in the body of a function declaration are the arguments of that function.
\end{enumerate}

We first define the semantics of the language using a small-steps operational semantics. Then we define a few operators on the language and exhibit some properties.
Finally we describe an algorithm to replace non destructive updates with destructive updates under certain conditions and prove that there is a bisimulation between programs before and after applying this algorithm. This proves that the execution of the program is not disturbed by the replacements and thus the correctness of the algorithm.



\subsection{Operational semantic}

A \emph{value} is either an integer $n \in \N$, a reference $r \in R$ representing an array (or pointer) or a function id $f \in F$ . The metavariable $v$ ranges over the set of all values: $V := \N \cup R \cup F$.\\

An \emph{evaluation context} (sometimes simply called \emph{context}) $E$ is an expression with an occurrence of a hole $\econt{}$. A context  and is of one of the forms
\begin{enumerate}
\itemsep-0.2em
\item $\econt{}$
\item $\cl{set(} x \cl{, } \econt{} \cl{); } e$
\item $\cl{pop(} \econt{} \cl{)}$
\item $E_1\econt{E_2}$ \ \ , where $E_1$ and $E_2$ are evaluation contexts.
\end{enumerate}

A \emph{redex} is an expression of the following form
\begin{enumerate}
\itemsep-0.2em
\item $x$
\item $X[y]$
\item $\cl{if (} x \cl{) } a \cl{ else } b $
\item $\cl{array(} x \cl{)}$
\item $X\cl{[(} x \cl{) := } y \cl{]}$
\item $X\cl{[(} x \cl{) <- } y \cl{]}$
\item $\cl{lambda(}  f \cl{, } m \cl{, } x_1 \cl{, } ... \cl{, } x_m \cl{)}$
\item $y\cl{(} x_1 \cl{, } ... \cl{, } x_n \cl{)}$
\item $f\cl{(} x_1 \cl{, } ... \cl{, } x_n \cl{)}$
\item $p\cl{(} x_1 \cl{, } ... \cl{, } x_n \cl{)}$
\item $\cl{set(} x \cl{, } v \cl{); } e$
\item $\cl{pop( } v \cl{)}$
\end{enumerate}

We define a \emph{local environment}, $s_i$, as a function ranging over the set $N$ of all variable names with values in $V$.\\
The \emph{stack state}, $s$, is a series of local environments: $s = (s_0, ... , s_n)$.\\
We call $[]$ the empty function and if $s_i$ is a local environment ranging over the variables $U$, we write $s_i \uplus (x \mapsto v)$ the function ranging over $U \cup \{x\}$ mapping $x$ to $v$ and $y$ to $s_i(y)$ for $y \neq x$. For $s = (s_0, ... s_n)$ a stack state, we write $s \uplus (x \mapsto v) := \left( s_0 \uplus (x \mapsto v), s_1, ... , s_n \right)$. We also define $s(x)$ as $s_i(x)$ where $\forall j < i, s_j(x)$ is not defined and to simplify notations, we call $s' :: s := (s', s_0, ... , s_n)$ and even $s' :: S  := (s' :: s, h)$.

The \emph{heap state} function, $h$ is mapping references $r$ to arrays of values, $V*$.\\

The \emph{store} (or \emph{state}) function, $S$, describing the state of the memory at a certain point in the execution is defined as the couple $(s, h)$.\\
We define $S(x) := s(x)$ and $S(r) := h(r)$.

A program is list of function declarations followed by a closed expression. For each function with id $f$ declared before the evaluation of the expression, we call $f_i$ the arguments of this function (variables) and $[f]$ its body (expression). A function is associated not only an id but also a number when declared. This number is used in lambda terms to refer to a function using a value.

The meta-variable conventions are that $x$ and $y$ range over variables, $X$ ranges over variables typed as arrays $n$ ranges over numbers, $p$ ranges over primitive function symbols, $f$ ranges over defined function symbols, $a$, $b$ and $e$ range over expressions. \\

A \emph{reduction} transforms a pair consisting of a redex and a store. The reductions corresponding to the redexes above are

\begin{enumerate}
\itemsep-0.2em
\item $<x,S> \ \longrightarrow \ < S(x), S> $
\item $<x \cl{[} y \cl{]} , S> \ \longrightarrow \ < h(s(x))(s(y)) , S>$
\item $<\cl{if (} x \cl{) } a \cl{ else } b, S>  \ \longrightarrow \ 
\left\lbrace \begin{array}{ll}
< \cl{pop(}a\cl{)} , [] :: S > & \text{if } s(x) = 0 \\
< \cl{pop(}b\cl{)} , [] :: S > & \text{otherwise}
\end{array} \right. $
\item $<\cl{array(} x \cl{)} , S > \ \longrightarrow \ <r, \left(s, h \uplus \left( r \mapsto (0)_{0 \leq i < s(x)} \right) \right) >$ where $r$ is a fresh pointer.
\item $< X \cl{[(} x \cl{) := } y \cl{]} , S> \ \longrightarrow \ < r, (s, h') >$ where $r$ is a fresh pointer and
$$ h' = h \uplus \left( r \mapsto h( s(X) ) \uplus \left( s(x) \mapsto s(y) \right) \right) $$
\item $< X \cl{[(} x \cl{) <- } y \cl{]} , S> \ \longrightarrow \ < X, (s, h') >$ where
\begin{eqnarray*}
h' &=& h \uplus \left( s(X) \mapsto h( s(X) ) \uplus \left( s(x) \mapsto s(y) \right) \right)
\end{eqnarray*}
\item $< \cl{lambda(} f \cl{, } m \cl{, } x_1 \cl{, } ... \cl{, } x_m \cl{)} , S > \ \longrightarrow \ < r, (s, h') > $ where $r$ is a fresh pointer and
$$h' = h \uplus ( r \mapsto (f, m, s(x_1), ... , s(x_m) ) ) $$
\item $< y\cl{(} x_1 \cl{, } ... \cl{, } x_n \cl{)}, S> \ \longrightarrow \ < \cl{pop(} [f] \cl{)}, s' :: S>$ where $E = h(s(y))$, $f=E(0)$, $m=E(1)$,
$$ s' : \left| \begin{array}{ccl}
\{ f_1, ... , f_{m+n} \} & \rightarrow & V \\
f_i & \mapsto & E(i+1) \ \ \text{ for } i \leq m \\
f_{m+i} & \mapsto & s(x_i) \ \ \text{ for } i \leq n
\end{array} \right. $$
\item $<f\cl{(} x_1, ... , x_n \cl{)} , S> \ \longrightarrow \ < \cl{pop(} [f] \cl{)}, \left( \biguplus_{1 \leq i \leq n} f_i \mapsto s(x_i) \right) :: S > $
\item $< p\cl{(} x \cl{, } y \cl{)}, S> \ \longrightarrow \ < p( s(x) , s(y) ), S>$ for binary operators.
\item $< p\cl{(} x \cl{)}, S> \ \longrightarrow \ < p( s(x) ), S >$ for the unary operator (\cl{not}).
\item $<\cl{set(} x \cl{, } v \cl{); } e, S> \ \longrightarrow \ < \cl{pop(}e\cl{)}, (x \mapsto v) :: S> $
\item $<\cl{pop(} v \cl{)}, ( (s_0, ... , s_n), h) > \ \longrightarrow \ <v, ( (s_1, ... , s_n), h) > $
\end{enumerate}

An evaluation step operates on a pair $<e, S>$ consisting of a closed expression and a store, and is represented as $<e, S> \ \longrightarrow \ <e', S'>$. If $e$ can be decomposed as a $E\econt{a}$ for an evaluation context $E$ and a redex $a$, then a step $<E\econt{a}, S> \ \longrightarrow \ <E\econt{a'}, S'>$ holds if $<a, s> \ \longrightarrow \ <a', s'>$
This is represented by the following rule.
\begin{prooftree}
\AxiomC{$<a, s> \ \longrightarrow \ <a', s'>$}
\UnaryInfC{$<E\econt{a}, s> \ \longrightarrow \ <E\econt{a'}, s'>$}
\end{prooftree}
One of the greatest advantage of using evaluation contexts is that we define the semantics of this language using only this one small-step rule.\\

The reflexive-transitive closure of $\longrightarrow$  is represented $\xrightarrow{*}$.
The computation of a program is defined as the evaluation of its expression $<e, S_0>$ on an empty store: $S_0 := (([]), [])$.
If $<e, S_0)> \xrightarrow{*} <e', S'>$ then we can prove that $e' \in V$ and the result of the computation is then defined as $eval_{h'}(e')$ where $eval_h$ is defined as follow:
$$ eval_h : \left|
\begin{array}{ccl}
V &\longrightarrow & E \\
n &\mapsto& n \in \N \\
r &\mapsto& \left( eval_h(u_i) \right)_{0 \leq i \leq n} \text{ with } (u_i)_{0 \leq i < n} := h(r)
\end{array}
\right. $$

\begin{theorem}
For all $<e, S_0> \ \xrightarrow{*} \ <v, (s,h)>$, $h$ is defined on $R \cap \left( \{v \} \cup Im(s) \cup Im(h) \right)$. All references stored in the stack or in the heap or reduced from an expression are defined in the heap state.
\end{theorem}
\begin{proof}
We proof this theorem by induction on the structure of the code.
\begin{enumerate}
\item Base cases: All redexes generating a fresh pointer (4, 5 and 7) modify the heap state to define it on that new pointer.\\
\item Induction step:
\begin{itemize}
\item References defined in the store are never undefined. If $<e, S> \ \longrightarrow \ <e', S'>$ and $h$ is defined on $r$ then $h'$ is also defined on $r$. This is easily proven since no redex remove a definition in the heap.
\item Whenever a value in the heap or in the store is modified, it is replaced with functions (redex 7), integers (redexes 4 and 7), values from the heap (redexes 2, 5, 6 and 8), values from the stack (redexes 1, 5, 6, 7, 8, 9, 10 and 11) or values reduced from an expression (redexes 12 and 13).
\end{itemize}
\end{enumerate}
\end{proof}


\subsection{Sets of variables}


We define the free variables, $Fv$, of an expression as the set of all variables that occur in that expression. For this study, we are only interested in variables that may refer to an array.\\

We also define the \emph{output} variables, $Ov(e)$, of an expression. This can be understood in three ways:
\begin{itemize}
\item This is the set of all variables that may have their value "trapped" into the expression $e$.
\item It corresponds to all the variables which content might get modified if $e$ gets modified in place.
\item It is the set of all variables which content the pointer corresponding to the evaluation of $e$ may point to.
\end{itemize}

Finally, we define the \emph{active} variables, $Av$, of an expression. In a similar way, this can be understood as:
\begin{itemize}
\item The set of all variables that may contain a reference to the expression $e$.
\item It corresponds to all the variables that could be accessed from the value returned by the expression.
\item It is the set of all variables which evaluation may be a pointer pointing to $e$.
\end{itemize}

If $X$ s a variable, $X^*$ refers to all the references $X$ may point to. It is obvious that if $X \in Av(e)$, then $X^* \in Av(e)$ as well. In that case, we voluntarily omit to mention $X^*$ in the definition of these set below.

\def\arraystretch{1.2}
\begin{center}
\begin{tabular}{|c|@{}c@{}|@{}c@{}|@{}c@{}|}
\hline
Expression & $Ov$ & $Av$ & $Fv$ \\ \hline
$n$ & $\emptyset$ & $\emptyset$ & $\emptyset$ \\ \hline
$X$ & $\{ X \}$ & $\{ X \}$ & $\{ X \}$ \\ \hline
$X\cl{[}x\cl{]}$ & $\{ X^* \}$ & $\{ X^* \}$ & $\{ X \}$ \\ \hline
\begin{minipage}{2cm}
\vspace{0.1cm}
$\cl{if (} x \cl{) } a$ \\
$ \cl{ else } \ \  b$
\vspace{0.1cm}
\end{minipage} & $Ov(a) \cup Ov(b)$ & $Av(a) \cup Av(b)$ & $Fv(a) \cup Fv(b)$ \\ \hline
$\cl{array(} x \cl{)}$ & $\emptyset$ & $\emptyset$ & $\emptyset$ \\ \hline
$X \cl{[(} x \cl{) := } y \cl{]}$ & $ \emptyset $ & $\{ X^*, y \}$ & $\{ X, y \}$ \\ \hline
$X \cl{[(} x \cl{) <- } y \cl{]}$ & $ \{ X \} $ & $\{ X, y \}$ & $\{ X, y \}$ \\ \hline
$\begin{array}{l}
\cl{lambda(}f\cl{, } m \cl{,} \\
\qquad x_1\cl{, }...\cl{, }x_m\cl{)}
\end{array}$ & $\emptyset$ & $\{ x_1, .. , x_m \}$ & $\{ x_1, .. , x_m \}$ \\ \hline
$y(x_1 \cl{, } ... \cl{, } x_n)$ & $\{ x_1, x^*_1, ... , x_n, x^*_n \}$ & $\{ x_1, ... , x_n \}$ & $\{ y, x_1, .. , x_n \}$ \\ \hline
$f(x_1 \cl{, } ... \cl{, } x_n)$  &
$\begin{array}{cl}
& \{x_i | f_i \in Ov([f]) \} \\
\cup & \{ x^*_i | f^*_i \in Ov([f]) \} \end{array}$ &
$\begin{array}{cl}
& \{x_i | f_i \in Av([f]) \} \\
\cup & \{ x^*_i | f^*_i \in Av([f]) \} \end{array}$
& $\{x_1, .. , x_n \}$ \\ \hline
$p(x_1 \cl{, } ... \cl{, } x_n)$ & $\emptyset$ & $\emptyset$ & $\emptyset$ \\ \hline
\begin{minipage}{2cm}
\vspace{0.1cm}
$\cl{set(}x\cl{, }a\cl{);}$ \\
$e$
\vspace{0.1cm}
\end{minipage} &
$\begin{array}{l}
Ov(e) \cup Av(a) - \{ x, x^* \} \\
\qquad \qquad \text{\ \ if }x^* \in Ov(e) \\
Ov(e) \cup Ov(a) - \{ x \} \\
\qquad \qquad \text{\ \ \ if }x \in Ov(e) \\
Ov(e)  \qquad \text{ \ \ \ otherwise}
\end{array}$
&
$\begin{array}{l}
Av(e) \cup Av(a) - \{ x, x^* \} \\
\qquad \text{ \ \ if $x $ or $x^* \in Av(e)$}\\
Av(e) \qquad \qquad \text{otherwise}
\end{array}$
& $Fv(a) \cup Fv(e) - \{ x \} $ \\ \hline
\end{tabular}
\end{center}
\def\arraystretch{1}


\begin{theorem}
For all expression $e$, $Ov(e) \subset Av(e) \subset Fv(e)$.
\end{theorem}
\begin{proof}
Simple induction proof on the expression form.
\end{proof}





\subsection{Update contexts}

The advantage of using contexts is to be able to place critical expressions like updates into a context where the evaluation order is well defined and we can identify expression evaluated before and after the reduction of a critical redex like a function call or a destructive update. These two being the only redexes that can modify the heap store in place.\\

We introduce \emph{update contexts} as an expression with a single occurrence of a hole:
\begin{enumerate}
\itemsep-0.2em
\item $\ucont{}$
\item $\cl{set(} x \cl{, } U \cl{); } e $
\item $\cl{set(} x \cl{, } a \cl{); } U $
\item $ \cl{if (} x \cl{) } U \cl{ else } b $
\item $ \cl{if (} x \cl{) } a \cl{ else } U $
\end{enumerate}

To define which update can be made destructively, we now build a reference graph in a context $U$. We define the pointer analysis of $U$ as $PA(U)$ where $PA(U)(X)$ is the set of all variables $X$ may point to in the context $U$. It is the smallest set containing $PA^0(U)(X)$ and close under $x \in PA(U)(X) \Longrightarrow PA(U)(x) \subset PA(U)(X)$.
\begin{eqnarray*}
PA^0(\ucont{} ) &:& \left| \begin{array}{lcl}
X   & \mapsto & \{ X, X^* \} \\
X^* & \mapsto & \{ X^* \}
\end{array}  \right. \\
PA^0( \cl{set(} x \cl{, } U \cl{); } e ) &:=& PA(U) \\
PA^0( \cl{set(} x \cl{, } a \cl{); } U )(X) &:=& PA^0(U)(X) \cup \left\lbrace \begin{array}{ll}
\{ x, x^* \} & \text{if $X \in Ov(a)$.} \\
\{ x^* \} & \text{if $X \in Av(a)$.} \\
Av(a) & \text{if $x^* \in PA^0(U)(X)$.} \\
\emptyset & \text{otherwise.}
\end{array} \right. \\
PA^0( \cl{if (} x \cl{) } U \cl{ else } b ) &:=& PA^0(U) \\
PA^0( \cl{if (} x \cl{) } a \cl{ else } U ) &:=& PA^0(U) 
\end{eqnarray*}
This will allow us to define the variables live in this context as well as the set of critical variables that could be modified by a destructive update.
\begin{itemize}
\item For $X$ a variable and $U$ a context, the set of critical variables $Cv(U)(X)$ contains all variables that may point to $X$ and all variable that may point to these variables and so on.
$$ Cv(U)(X) := \{ \ y \ | \ X \in PA(U)(y) \ \} = PA(u)^{-1}(\{X \}) $$
\item The set $Lv(U)$ of the variables live in the context $U$ are the variables that could be evaluated after the hole the in the context and the variables that these variables may point to and so on.
\begin{eqnarray*}
Lv^0(\ucont{} ) &:=& \emptyset \\
Lv^0( \cl{set(} x \cl{, } U \cl{); } e ) &:=& Fv(e) \cup Lv^0(U) \\
Lv^0( \cl{set(} x \cl{, } a \cl{); } U )(X) &:=& Lv^0(U) \\
Lv^0( \cl{if (} x \cl{) } U \cl{ else } b ) &:=& Lv^0(U) \\
Lv^0( \cl{if (} x \cl{) } a \cl{ else } U ) &:=& Lv^0(U) \\
Lv(U) &:=& \bigcup_{x\in Lv^0(U)} PA(U)(x)
\end{eqnarray*}
\end{itemize}
%The set $Lv(U)$ of the variables live in the context $U$ are the variables that could be evaluated after the hole the in the context and the variables that these variables may point to and so on. It is defined as the smallest set containing $Lv^0(U)$ an close under 
%$$ PA(U)(Lv(U)) \subset Lv(U) $$
%where $Lv^0(U)$ is defined as
%\begin{eqnarray*}
%Lv^0(\ucont{} ) &:=& \emptyset \\
%Lv^0( \cl{set(} x \cl{, } U \cl{); } e ) &:=& Fv(e) \cup Lv^0(U) \\
%Lv^0( \cl{set(} x \cl{, } a \cl{); } U )(X) &:=& Lv^0(U) \\
%Lv^0( \cl{if (} x \cl{) } U \cl{ else } b ) &:=& Lv^0(U) \\
%Lv^0( \cl{if (} x \cl{) } a \cl{ else } U ) &:=& Lv^0(U)
%\end{eqnarray*}
When we consider turning a non destructive update $X\cl{[(}x\cl{) := } \cl{y} \cl{]}$ in a context $U$ into a destructive update, we want to make sure that critical variables are not live $U$.
$$ Cv(U)(X) \cap Lv(U) = \emptyset $$




\subsection{Analysis}

We consider here a function $f$ which declaration body $e$ doesn't contain any destructive update before the analysis. The reason is that a safe, naive translation from PVS to this language would only perform non destructive updates.

Intuitively, if a function $f\cl{(}f_1\cl{, } ... \cl{, } f_n\cl{) = } e$ contains a non destructive update in a context $e = U\ucont{X\cl{[(}x\cl{) := }y\cl{]}}$. That update can be turned into a destructive update if none of the variables that may be aliased to $X$ are live in the context.
$$ Cv(U)(X) \cap Lv(U) = \emptyset $$
This way all this variables that may point to $X$ are never used after the update. Since they are the only variables whose evaluation is modified by making the update destructive, we can say that this is a safe transformation.\\

The problem is that some of these variables possibly pointing to $X$ might be included in the set of arguments of $f$: $\{f_1, ... , f_n\}$. And we can't assume anything about these variables since we don't have any information regarding the context in which the function $f$ is called.\\

We define the bang analysis $BA(f)$ as the set of all variables that are involved in a destructive update or are destructive arguments in a call to a destructive function:
$$ BA(f) \ \ := \ \ \left( \bigcup_{e = U\ucont{X\cl{[(}x \cl{) <- } y \cl{]} }}  Cv(U)(X) \right) \ \ \cup \ \ \left( \bigcup_{e = U\ucont{g\cl{(} x_1\cl{,} ... \cl{,} x_n \cl{)}}} Cv(U)( \{ x_i | g_i \in BA(g) \}) \right)$$
Basically $BA(f)$ is the set of all critical variables in the evaluation of a function call to $f$.

We define two versions of all function declared. A non destructive version $f$ with body $e_{nd}$ and a destructive version $f^d$ with body $e_d$.
Both new definitions may only differ from the original body $e$ of $f$ in some very specific substitutions: non destructive updates in $e$ may be destructive in $e_{nd}$ and $e_d$ and function calls to a function $g$ may become function calls to $g^d$ with the same arguments in $e_d$ and $e_{nd}$.\\

These functions use two different strategies:
\begin{itemize}
\item The second consists in allowing destructive updates of variables that could be aliased arguments. We however keep track of these arguments and only call this function when we are sure the arguments are safe in the context of the call. 
The yields the definition $e_d$ of $f^d$ verifying the following properties:
\begin{itemize}
\item If $e = U\ucont{X\cl{[(}x \cl{) := } y \cl{]}}$ and $U'$ is the corresponding context in $e_d$ then
$$ e_d = U'\ucont{X\cl{[(}x \cl{) <- } y \cl{]}} \ \Longleftrightarrow \ Cv(U')(X) \cap Lv(U') = \emptyset $$
\item If $e = U\ucont{g^d\cl{(}x_1 \cl{,} ... \cl{,} x_n \cl{)}}$ and $U'$ is the corresponding context in $e_d$ then the condition for $e_d = U'\ucont{X\cl{[(}x \cl{) <- } y \cl{]}}$ is
$$ \text{All } Cv(U')(x_i) \text{ for } g_i^d \in BA(g^d) \text{ and } Lv(U') \text{ are pairwise disjoints.} $$
\end{itemize}
\item The first consists in forbidding the use of destructive updates which argument may be pointing to by arguments. This is equivalent to saying that all arguments of non destructive functions are live in all contexts (or just in the empty context).
This yields the new definition $e_{nd}$ of $f$ verifying the following properties:
\begin{itemize}
\item If $e = U\ucont{X\cl{[(}x \cl{) := } y \cl{]}}$ and $U'$ is the corresponding context in $e_{nd}$ then
$$ e_{nd} = U'\ucont{X\cl{[(}x \cl{) <- } y \cl{]}} \ \ \Longleftrightarrow \ \  Cv(U')(X) \cap \left( Lv(U') \cup \{f_1, ... , f_n \} \right) = \emptyset $$
\item If $e = U\ucont{g^d\cl{(}x_1 \cl{,} ... \cl{,} x_n \cl{)}}$ and $U'$ is the corresponding context in $e_{nd}$ then the condition for $e_d = U'\ucont{X\cl{[(}x \cl{) <- } y \cl{]}}$ is
$$ \text{All  } Cv(U)(x_i) \text{ for } g^d_i \in BA(g^d) \text{ and } Lv(U) \cup \{f_1, ... , f_n \} \text{ pairwise disjoints.}  $$
\end{itemize}
\end{itemize}
\begin{proposition}
For all non destructive version of a function $f$, $ BA(f) = \emptyset$.
\end{proposition}

\subsection{Proof of bisimulation}

We define the accessible cells, from a variable $X$ given a store $S$ as the set of all references (heap store entries) that can be accessed from the variable $X$.
$$ Ac(S)(X) := R \cap S^{\infty}(X)$$
We extend that definition of S to star variables and of $Ac$ to expressions and updates
\begin{eqnarray*}
S(X^*) := Ac(S)(X) \\
Ac(S)(e) &:=& Ac(S)( Av(e) ) \\
Ac(S)(U) &:=& Ac(S)( Lv(U) )
\end{eqnarray*}
It correspond to the only references already created in the heap store that can still be accessed in the context or expression. \\

The proof of correctness relies on three main invariants:
\begin{enumerate}
\item The function calls to $f$ or $f^d$ have the same evaluation. This means they can't be told apart by looking only at the value of the result. However they differ in the use of their arguments.
\item When the function call $f(x_i)$ is evaluated with a store $S$, the only references which value could be modified is $\bigcup_{f^{(*)}_i \in BA(f)} S\left(x^{(*)}_i\right)$.
\item The union above is always a pairwise disjoint union.
\end{enumerate}
These properties are obviously true before the analysis since $f = f^d$, $BA(f) = \emptyset$ for all function and no reference ever have its value modified.\\

The destructive and non destructive versions of a function $f$ are built from the original definition $e$ by replacing function calls (updates can be considered as a function call). To prove the correctness of this algorithm we need to prove that the three invariants described above are preserved between programs before and after a single replacement. \\

We consider the replacement of $g$ to $g^d$ in a function $f^d$ of body $e =  U\ucont{g^d\cl{(}x_i \cl{,} y_j \cl{,} z_k \cl{)}}$ with $x_i$ variables corresponding to the critical arguments $g^d_i \in BA(g^d)$, $y_j$ corresponding to arguments that are active in the body of $e$ and $z_k$ arguments that are not arrays or are not in either of the previous sets. \\

We have the following hypothesis
\begin{itemize}
\item[$(H1)$] All $Cv(U)(x_i)$ and $Lv(U)$ are pairwise disjoints (Analysis).
\item[$(H2)$] The evaluation of the call to $g^d$ with a store $S$ is the same than if $g$ was called.
\item[$(H3)$] The only references which value may be modified during the evaluation of the call with a store $S$ is the union $\bigcup_{f^{(*)}_i \in BA(f)} S\left(x^{(*)}_i\right)$.
\item[$(H4)$] $f$ will always be called in an evaluation context with a store $S$ such that the sets $S\left(f^{(*)}_i\right)$ are disjoint for all $f^{(*)}_i \in BA(f)$.
\end{itemize}
\begin{proposition}
For all store $S$ with which this function call is evaluated, the sets $S\left(x^{(*)}_i\right)$ are pairwise disjoint.
\end{proposition}
\begin{proof}
$(H1)$ and $(H4)$.
\end{proof}

\begin{proposition}
For all store $S$ with which the function call is evaluated, the sets $\bigcup S\left(x^{(*)}_i\right)$ and $Ac(S)(U)$ are disjoints.
\end{proposition}
\begin{proof}
$(H1)$ and $(H4)$.
\end{proof}

\begin{proposition}
When a call to $f^d$ is evaluated with a store $S$ the only references that may be modified in $S$ is $\bigcup_{f^{d,(*)}_i \in BA(f)} S\left(x^{(*)}_i\right)$
\end{proposition}
\begin{proof}
By definition of $BA(f)$, all the arguments that may point to references that could newly be modified are added to $BA(f)$.
\end{proof}

\begin{proposition}
The function calls to $f$ or $f^d$ have the same evaluation.
\end{proposition}
\begin{proof}
The only modification in the evaluation of a function call to the new $f^d$ is the function call to $g^d$. That function call has the same evaluation, $(H2)$, and the only references it may modify, $(H3)$ are never used afterward in the evaluation of the body of $f^d$, $(H1)$.
\end{proof}

This analysis would have worked as well for non destructive versions of functions and for the replacement of an update rather than a function call.



\begin{theorem}
If $<e_1, (s_1, h_1)> \ \longrightarrow \ <e_2, (s_2, h_2)>$ then $<e_1, (s_1, h'_1)> \ \longrightarrow \ <e_2, (s_2, h'_2)>$ where $h'_i = h_i|_{Lc(S_1)(e_1)}$.
\end{theorem}
\begin{proof}
It can easily be verified for every redex. When $a = U\ucont{b}$, we have $Lc(a) = Lc(U) \cup Lc(b)$ and the inductive step is proved .
\end{proof}









\newpage
\section{Conclusion}
\label{sec:Concl}

We have described the general architecture of the translator from PVS to the C language we implemented and integrated into PVS. We have provided a few examples of its execution on simple examples to illustrate its mechanisms.

We have described the update issue and various ways to deal with it. Both the use of a reference counting garbage collector and an analysis of the intermediate language were implemented.

We have defined the semantics of the intermediate language which allowed us to prove the correctness of the analysis that is performed on it to eliminate non destructive updates.

This tool allows to efficiently execute PVS code for debugging and testing purposes and to easily integrate C code into actual systems where the C and C++ are common development languages.



\subsection{Difficulties and successes}

This project was a great challenge and an opportunity for me to conduct my own autonomous research on a subject I chose. The development of the working translator was also the occasion for me to discover new tools, formal techniques and learn a lot about computer science in general.


\subsubsection*{Working with new languages and tools}

To be able to translate PVS, I had to fully understand not only the syntax and semantics of the PVS language but also the structure of the PVS API written in Common Lisp. This means I also had to learn Common Lisp which I decided then to use to write the translator mostly because it made the integration of the native PVS parser and typechecker easier. Finally I had to discover the C language which I only had a basic knowledge of.


\subsubsection*{Integrating the GMP library}
In PVS (and in other languages such as Common Lisp or Python), the \cl{integer} type represent the whole set $\Z$ of all relative numbers (and \cl{rational} also describes the whole set $\Q$).
To implement that in C, we need more than the finite types \cl{int}, \cl{long}, etc.

\begin{figure}[!ht]
\cl{norm(x:int, y:int):int = x*x + y*y}
\begin{lstlisting}
void norm(mpz_t result, mpz_t x, mpz_t y) {
  mpz_t aux1;
  mpz_init(aux1);
  mpz_mul(aux1, x, x);
  mpz_clear(x);
  mpz_t aux2;
  mpz_init(aux2);
  mpz_mul(aux2, y, y);
  mpz_clear(y);
  mpz_add(result, aux1, aux2);
  mpz_clear(aux1);
  mpz_clear(aux2);
}
\end{lstlisting}
\caption{Example of the GMP library use}
\label{fig:exGMP}
\end{figure}

The translator uses the GMP library which introduces the types \mpzt and \mpqt. These types are pointers (technically arrays) to structures and they had to be used with caution (allocation, freeing, ...).

For example (Figure~\ref{fig:exGMP}), a function returning a \mpzt should actually take a first \mpzt argument and set it to the return value. Its return type being \cl{void}.


\subsection{What's left to be done ?}

One of my biggest regret was not having the time to finish the translator and properly implement closures. Some work is already done in that direction though. It relies on a C structure to represent a closure:
\begin{lstlisting}
struct r_list_int {
   int (*body)(void* env, void* args);  // body is a function pointer
   void* env;                           // env contains the environment variables
   void* args;                          // args will contain the arguments
};
\end{lstlisting}


Since the translator's correctness itself has not be proven, there is no formal guarantee that the semantic will be preserved during the translation. In particular, even if some properties were proven on a certain PVS model, its translation to C could not verify these properties. This tool certainly does not allow the generation of high insurance code. The only way to do that would be to formally prove the correctness of the translator. The CompCert C compiler (\href{http://compcert.inria.fr}{http://compcert.inria.fr/compcert-C.html}), is an example of such a proven translator.


\subsection{My stay at SRI}

Besides the conception and implementation of the PVS to C translator, my stay at SRI International was rich in interesting events. 

The first weeks of my stay were the occasion to discover PVS and Coq as I started working on a translator Coq to PVS. With Robin, we also wrote as an exercise a basic linear algebra library.

I discovered Lisp the hard way while discovering the middle- and back-end of the PVS API. Among other excerises, I decided to write a Common Lisp parser to help me understand the huge architecture of the PVS API code (classes definitions, inheritances and organization, function dependances, ...)

I also have had the chance to attend to the many interesting seminars SRI hosted every week. The "Crazy Ideas" seminar hosted every other week was a ...

The SRI also organized a Summer School to which we were allowed to attend and which was very interesting.

Shankar never hesitated to include us in many project

I've been included in the HACMS project which was very interesting.
With other:
Correcting translator PVS to SMT-LIB

Discovering PVS :
Translating Coq proofs to PVS
PVS library for basic linear algebra

Robin project, HACMS \\
Contest week-end 14-15 June \\
Summer School \\
Parsing Lisp code -> generate HTML architecture file\\
Correcting translator PVS to SMT-LIB




\printbibliography

\appendix

\newpage
\section{PVS Syntax and CLOS representation}

\begin{figure}[h]
\input{includes/PVS-expr}
\caption{Syntax of the PVS subset of the translator}
\label{fig:PVSsyntax}
\end{figure}

\begin{figure}[!ht]
\input{includes/PVS-CLOS}
\caption{(Partial) CLOS representation of PVS syntax}
\label{fig:PVS-CLOS}
\end{figure}

\newpage
\section{PVS type system and CLOS representation}

\begin{figure}[!ht]
\input{includes/PVS-type}
\caption{Fragment of the PVS type system}
\label{fig:PVS-types}
\end{figure}


\begin{figure}[!ht]
\input{includes/PVS-CLOS-type}
\caption{(Partial) CLOS representation of PVS types}
\label{fig:PVS-CLOS-types}
\end{figure}


\newpage
\section{Intermediate languages}

\begin{figure}[!ht]
\input{includes/aux-expr}
\caption{Syntax of the intermediate language}
\label{fig:aux-syntax}
\end{figure}

\newpage
\begin{figure}[!ht]
\input{includes/C-expr}
\caption{Syntax of the representation language. Every $Expr$ is typed.}
\label{fig:Csyntax}
\end{figure}



\newpage
\section{Rules}
\label{Rules}


\begin{figure}[!ht]
\begin{tabular}{|p{5.5cm}|p{5.5cm}|p{6cm}|}
\hline
             & \cl{A} \safe & \cl{A} not \safe \\ \hline
\cl{A} \mut  & Replace every occurrence of the variable \cl{B} by the variable \cl{A} & \begin{lstlisting}
B = GC_malloc(...);
for(i ...) {
  B[i] = A[i];
}
\end{lstlisting} \\ \hline
\cl{A} \nmut & \begin{lstlisting}
if (GC_count(A) == 1) {
  B = A;
} else {
  B = GC_malloc(...);
  for(i ...) {
    B[i] = A[i];
  }
}
\end{lstlisting} & \begin{lstlisting}
B = GC_malloc(...);
for(i ...) {
  B[i] = A[i];
}
\end{lstlisting} \\ \hline
\end{tabular}
\caption{Rules for \cl{copy(B, A)}}
\end{figure}



\begin{figure}[!ht]
\begin{tabular}{|p{5.5cm}|p{5.5cm}|p{6cm}|}
\hline
             & \cl{A} \safe & \cl{A} not \safe \\ \hline
\cl{A} \mut  & Replace every occurrence of the variable \cl{B} by the variable \cl{A} & \begin{lstlisting}
B = GC_malloc(...);
for(i ...) {
  B[i] = A[i]
}
\end{lstlisting} \\ \hline
\cl{A} \nmut & Replace every occurrence of the variable \cl{B} by the variable \cl{A} & \begin{lstlisting}
B = GC( A );
\end{lstlisting}
If \cl{B} is flagged \dupl then \cl{A} must be too.
\\ \hline
\end{tabular}
\caption{Rules for \cl{set(B, A)}}
\end{figure}



\begin{figure}[!ht]
\begin{tabular}{|p{5.5cm}|p{5.5cm}|p{6cm}|}
\hline
             & \cl{A} \safe & \cl{A} not \safe \\ \hline
\cl{A} \bang  &
\begin{lstlisting}
f_d(A)
\end{lstlisting} & \begin{lstlisting}
f(A)
\end{lstlisting} \\ \hline
\cl{A} not \bang & \begin{lstlisting}
f(A)
\end{lstlisting} & \begin{lstlisting}
f(A)
\end{lstlisting} \\ \hline
\end{tabular}
\caption{Rules for \cl{f(A)} with \cl{A} flagged \bang in the destructive version}
\end{figure}


\begin{figure}[!ht]
\begin{tabular}{|p{5.5cm}|p{5.5cm}|p{6cm}|}
\hline
             & \cl{A} \safe & \cl{A} not \safe \\ \hline
\cl{A} \bang  &
\begin{lstlisting}
f(A)
\end{lstlisting} & \begin{lstlisting}
copy(B, A)
f(B)
\end{lstlisting} \\ \hline
\cl{A} not \bang & \begin{lstlisting}
f(A)
\end{lstlisting} & \begin{lstlisting}
f(A)
\end{lstlisting} \\ \hline
\end{tabular}
\caption{Rules for \cl{f(A)} with \cl{A} flagged \dupl}
\end{figure}






\newpage
\
\newpage

\section{Examples}
Here are a few simple example to get an idea of the optimization that occur on the intermediate language. Following is a complete example of a program generating an array of pseudo random numbers and sorting it with the insertion sort algorithm.

\begin{figure}[!ht]
\begin{tabular}{|p{5.2cm}|p{5.8cm}|p{6cm}|}
\hline
\begin{center}
PVS code
\end{center} &
\begin{center}
Intermediate language code\\
(before analysis - with types)
\end{center} &
\begin{center}
C code generated
\end{center} \\ \hline

\begin{lstlisting}
f(A:Arr):Arr = A
\end{lstlisting} &
\cl{f: ( int* A ) -> int*} \newline
\cl{A} &
\begin{lstlisting}
int* f(int* A) {
  return A;
}
\end{lstlisting} \\ \hline

\begin{lstlisting}
f(A:Arr):Arr =
  let B = A in B
\end{lstlisting} &
\cl{f: ( int* A ) -> int*} \newline
\cl{set(B, A);} \newline
\cl{B} &
\begin{lstlisting}
int* f(int* A) {
  return A;
}
\end{lstlisting} \\ \hline

\begin{lstlisting}
f(A:Arr):Cint =
 let B = A in
  A(0) + B(0)
\end{lstlisting} &
\cl{f: ( int* A ) -> int} \newline
\cl{set(B, A);} \newline
\cl{+( A(0), B(0) )} &
\begin{lstlisting}
int* f(int* A) {
  int* B = (int*) GC( A );
  int result = A[0] + B[0];
  GC_free(B);
  GC_free(A);
  return result;
}
\end{lstlisting} \\ \hline

\begin{lstlisting}
f(A:Arr):Arr =
  let B = A in
    A WITH [(0) := B(0) ]
\end{lstlisting} &
\cl{f: ( int* A ) -> int} \newline
\cl{set(B, A);} \newline
\cl{set(L, 0);} \newline
\cl{set(R, B(0) );} \newline
\cl{set(result, A[(L) := R] );} \newline
\cl{result} &
\begin{lstlisting}
int* f_d(int* A) {
  int* B = GC_malloc(...);
  for(i ...)
     B[i] = A[i];
  int L = 0;
  int R = B[0];
  GC_free(B);
  int* result = GC( A );
  GC_free(A);
  result[L] = R;
  return result;
}
\end{lstlisting} \\ \hline
\end{tabular}
\caption{Examples of setting variables}
\end{figure}


\begin{figure}[!ht]
\begin{tabular}{|p{5.5cm}|p{5.5cm}|p{6cm}|}
\hline
\begin{center}
PVS code
\end{center} &
\begin{center}
Intermediate language code
\end{center} &
\begin{center}
C code generated
\end{center} \\ \hline

\begin{lstlisting}
f(A:Arr):Arr =
  A WITH [(0) := 0]
\end{lstlisting} &
\cl{f: ( int* A ) -> int*} \newline
\cl{set(L, 0);} \newline
\cl{set(R, 0);} \newline
\cl{A[(L) := R]} &
\begin{lstlisting}
int* f(int* A) {
  int L = 0, R = 0;
  int* result;
  if( GC_count(A) == 1 ) {
    result = GC( A );
  } else {
    result = GC_alloc(...);
    for(i ...)
      result[i] = A[i];
  }
  result[L] = R;
  GC_free( A );
  return result;
}

int* f_d(int* A) {
  int L = 0, R = 0;
  A[L] = R;
  return A;
}
\end{lstlisting} \\ \hline

\begin{lstlisting}
f(A:Arr):Arr =
 let B = A WITH[(0):=0]
 in A WITH[(0) := B(0)]
\end{lstlisting} &
\cl{f: ( (A, int*) ) -> int*} \newline
\cl{set(L1, 0);} \newline
\cl{set(R1, 0);} \newline
\cl{set(B, A[(L1) := R1] );} \newline
\cl{set(L2, 0);} \newline
\cl{set(R2, B(0));} \newline
\cl{A[(L2) := R2] );} &
\begin{lstlisting}
int* f(int* A) {
  int R1 = 0, L1 = 0;
  B = GC_alloc(...);
  for(i ...)
    B[i] = A[i];
  B[L1] = R1;
  int R2 = 0, L2 = B[0];
  result = GC_alloc(...);
  for(i ...)
    result[i] = A[i];
  result[L2] = R2;
  GC_free(A);
  GC_free(B);
  return result;
}

int* f_d(int* A) {
  int R1 = 0, L1 = 0;
  B = GC_alloc(...);
  for(i ...)
    B[i] = A[i];
  B[L1] = R1;
  int R2 = 0, L2 = B[0];
  A[L2] = R2;
  GC_free(B);
  return A;
}
\end{lstlisting} \\ \hline
\end{tabular}
\caption{Examples of copying variables}
\end{figure}



\newpage
\begin{figure}
\begin{lstlisting}[language=TeX]
benchmark : THEORY
BEGIN

% We use the Lehmer random number generator
% with the following parameters

% n      = 59557   big prime number picked from
%                  http://primes.utm.edu/lists/small/10000.txt
% length = 1000
% g      = 12345
% X_0    = 9876

  Val : TYPE = subrange(0, 59557)
  Ind  : TYPE = below(20000)
  Arr  : TYPE = [ Ind -> Val ]
  
  A : VAR Arr
  i : VAR Ind
  v : VAR Val
  
  init(A, i, v): RECURSIVE Arr =
    let B = A with [(i) := v] in
      if i >= 999 then B	
      else init(B, i+1, rem(59557)(12345 * v) ) endif
  MEASURE 999 - i
  
  J :Arr = lambda(k:Ind): 999 - k
  Z :Arr = lambda(x:Ind) : 0
  T :Arr = init(Z, 0, 9876)
  
  
  insert(A, v, i): RECURSIVE Arr =
    IF (i = 0 OR v >= A(i - 1))
    THEN A WITH [(i) := v]
    ELSE insert(A WITH [(i) := A(i - 1)], v, i - 1)
    ENDIF
    MEASURE i

  insort_rec(A, (n:upto(1000)) ): RECURSIVE Arr =
    IF n < 1000 THEN
      let An = A(n) in
        insort_rec( insert(A, An, n), n + 1 )
    ELSE A ENDIF
    MEASURE 1000 - n

  insort(A): Arr = insort_rec(A, 0)
  
  tsort: Val = insort(T)(0)
  jsort: Val = insort(J)(0)
  
END benchmark
\end{lstlisting}
\caption{Full PVS example - C translation}
\end{figure}


\begin{figure}
\begin{lstlisting}
unsigned long int* init(unsigned long int* A, int i, unsigned long int v) {
  A[i] = v;
  if ((i >= SIZE_1)) {
    return A;
  } else {
    return init( A , (i + 1) , ((12345 * v) % 59557) );
  }
}

unsigned long int J(int k) {
  return (unsigned long int) (SIZE_1 - k);
}

unsigned long int Z(int x) {
  return (unsigned long int) 0;
}

unsigned long int* T() {
  unsigned long int* aux = GC_malloc(SIZE, sizeof(unsigned long int) );
  int i;
  for(i = 0; i < SIZE; i++)
    aux[i] = Z( i );
  return init( aux , 0 , (unsigned long int) 9876 );
}

unsigned long int* insert(unsigned long int* A, unsigned long int v, int i) {
  if (((i == 0) || (v >= A[(i - 1)]))) {
    A[i] = v;
    return A;
  } else {
    unsigned long int res = A[(i - 1)];
    A[i] = res;
    return insert( A , v , (i - 1) );
  }
}

unsigned long int* insort_rec(unsigned long int* A, int n) {
  if ((n < SIZE)) {
    unsigned long int An = A[n];
    return insort_rec( insert( A , An , n ) , (n + 1) );
  else
    return A;
}

unsigned long int* insort(unsigned long int* A) { return insort_rec( A , 0 ); }

unsigned long int tsort() { return insort( T() )[0]; }

unsigned long int jsort() {
  unsigned long int* aux;
  aux = GC_malloc(SIZE, sizeof(unsigned long int) );
  int i;
  for(i = 0; i < SIZE; i++) {
    aux[i] = J( i );
  }
  return insort( aux )[0];
}
\end{lstlisting}
\caption{Full PVS example - C translation}
\end{figure}




\end{document}
