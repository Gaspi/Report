\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}

\usepackage[left=1.5cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{xcolor}
\usepackage[colorlinks]{hyperref}
\usepackage{graphicx}

\usepackage{includes/bussproofs}

% --- CSL part
% \usepackage{natbib}
\input{includes/pvstex}
\usepackage{includes/makebnf}

\usepackage[space]{grffile}
\usepackage{pdfpages}

\usepackage[%
  backend=biber,
  style=alphabetic,
  backref=true,
  backrefstyle=all+,
  hyperref=true,
]{biblatex}

\bibliography{allbib}




% --- Partie code
\usepackage{listings}
\lstset{language=C,
        showstringspaces=false,
        basicstyle=\footnotesize\ttfamily,
        captionpos=b,
        stepnumber=1,
        keywordstyle=\bfseries\color{green!40!black},
        commentstyle=\itshape\color{purple!40!black},
        identifierstyle=\color{blue},
        stringstyle=\color{red}}

\newcommand{\cl}[1]{\texttt{#1}}

% --- Parti math. (app.)
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{remark}[theorem]{Remark}

% Mathematic abbreviations
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}

\newcommand{\mpzt}{ \texttt{ mpz\_t } }
\newcommand{\mpqt}{ \texttt{ mpq\_t } }

\newcommand{\mut}{\textbf{mutable }}
\newcommand{\nmut}{\textbf{non-mutable }}
\newcommand{\bang}{\textbf{mutable }}
\newcommand{\safe}{\textbf{safe }}
\newcommand{\dupl}{\textbf{duplicated }}

% evaluation context hole
\newcommand{\econt}[1]{[#1]}
% update context hole
\newcommand{\ucont}[1]{\{#1\}}


\setcounter{tocdepth}{2}

\begin{document}

\includepdf[pages={1}]{includes/frontpage/frontpage.pdf}

\newpage
\
\vspace{1.5in}
\begin{abstract}
PVS (standing for Prototype Verification System), is an Open Source project developed by CSL at SRI International and aiming to be both a semi-automated theorem prover providing formal support for conceptualization and debugging in the early stages of the design of hardware or software systems and a programming language. The evaluation of PVS expressions relies so far on a build-in PVS interpreter based on Common Lisp, called "Ground Evaluator". In order to allow the integration of PVS code as well as its fast execution for debugging and testing purposes, we describe here a translator of a subset of PVS to the language C.\\

The update of aggregate data structure, such as arrays, are frequent in functional programs and requires copying before being updated which is a significant source of space/time inefficiencies.
However the execution of updates by copying is often redundant and could be safely implemented by means of destructive, in-place updates in an imperative program.
We describe a simple method for analyzing and replacing the safe updates in an imperative program with destructive, in-place update.
This method has been implemented to optimize the PVS translator.
\end{abstract}

\vspace{1in}
\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}
I would like to thank my supervisor, Natarajan Shankar, for his help, explanations and suggestions as well as for the many enlightening discussions we had during this internship. I also thank Sam Owre for his explanations of the PVS API and Common Lisp in general, Robin Larrieu, from Polytechnique who shared an office and a lot of good ideas with me. I thank all of my teachers from  LIX who made this internship possible, with a special mention to Stéphane Graham-Lengrand and Benjamin Doerr who recommended me.
Finally, I thank all the people at the CSL, for their welcome, the interesting discussions I had with them, and for creating an exciting and inspiring environment for work. 
A special thank Lori Truitt for all the help she provided with administrative paperwork.
\end{abstract}


\newpage
\tableofcontents
\newpage

\section{Introduction}


In this section, we quickly describe PVS and the previous effort made in its translation. Then, we give in Section~\ref{sec:UpdateExpr} an overview of the different steps in the process of translating a functional, higher order, specification language into an imperative, low-level language such as C. We provides a few detail on the implementation of our translator and give examples of its execution. In Section~\ref{sec:UpdateExpr} we describe the issue of the translation of updates expressions and describe a few solutions, two of them being implemented in the translator. Finally we focus on the implemented static analysis in Section~\ref{sec:StaticAnal} and try to prove its correctness.



\subsection{PVS Overview}

PVS  (Prototype Verification System) is an environment for specification and proving. The main purpose of PVS is to provide formal support for conceptualization and debugging in the early stages of the life cycle of the design of hardware or software systems. In these stages, both the requirements and designs are expressed in abstract terms that are not necessarily executable. The best way to analyze such an abstract specification is by attempting proofs of desirable consequences of the specification. Subtle errors revealed by trying to prove the properties are costly to detect and correct at later stages of the design life cycle. \\

The specification language of PVS is built on higher-order logic: functions can be treated like primitive types: functions can take functions as arguments and return them as values, quantification (universal and existential) can be applied to function variables. Specifications can be constructed using definitions and axioms. \\

PVS typechecking is not decidable and thus whenever the typechecker encounters a non trivial constraint for an expression to be type-correct, it relies on \emph{Type-Correctness Condition} (TCC), a formula that has to be proved by the user for the expression to actually be typed correct. For instance, trying to divide by some variable $x$ will automatically generate a TCC for the user to prove that that $x$, in the context of the call, can not be zero. \\

A PVS file consists in one or several theories, that are somewhat similar to modules in OCaml and Python, or to packages in Java. The body of a theory consists in a serie of declarations of the form \cl{name:sort = def} where \cl{sort} is the “sort” of the declaration and \cl{def} is a PVS expression which can be a term expression (syntax described in Figure~\ref{fig:PVSsyntax}) or a type expression (syntax described in Figure~\ref{fig:PVS-types}). When the \cl{= def} part is omitted, the declaration is uninterpreted and the name now refers to some abstract value of \cl{sort}. See Figure~\ref{fig:PVSbenchmark} for an example of a theory. \\

The sort of the declaration can be:
\begin{itemize}
\item A PVS type expression (lines 15-17 in the PVS example), in which case the declaration defines a new value of that type. A TCC is generated to prove that the definition is of the given type unless no definition is given. In that case, a TCC might be generated to prove the type is non empty.
\item \cl{TYPE} or \cl{NONEMPTY\_TYPE} (or \cl{TYPE+}), in which case the declaration defines a new type. A TCC might be generated to guarantee the non emptiness.
\item A theorem-like keyword such as \cl{THEOREM} or \cl{LEMMA}, in which case the declaration defines a new theorem. A proof obligation is generated, and the theorem can be used in proofs in the remaining declarations
in the file.
\item An axiom-like keyword such as \cl{AXIOM} or \cl{POSTULATE}, in which case the declaration introduces a new axiom. No proof obligation is generated and the proposition can be used in proofs in the remaining declarations in the file.
This can obviously introduce inconsistencies, and should be used with much care. It is often used in conjunction with uninterpreted declarations to define types or terms axiomatically instead of providing a definition.
\end{itemize}

In addition to that, the PVS \cl{DATATYPE} mechanism allows to define recursive sum types with constructors, accessors, and recognizers. There is no polymorphism in PVS, however \emph{theory parameters} allow to have some sort of genericity. Finally, another mechanism that we left out and that is worth mentioning is the \cl{IMPORTING} keyword which has a visibility effect and is required in the PVS implementation to be able to talk about a theory inside another theory.


\subsection{Why translate PVS ?}

Specification languages such as PVS are made to be expressive rather than executable allowing the conceptualization, design, modelization and analysis of complex systems described at a higher level than a programming language. \\

However such systems are themselves made to be later executed and integrated into physical systems. For that reason, a model of a system needs to be turned into executable code implemented into a programming language. This can be done manually with the risk of making human mistakes in the translation process or this can be left to a automated translator which would preserve the high insurance properties that were proven on the model. Besides, the ability to run a model during its development phase allows debugging and testing.




\subsubsection*{The HACMS Project}

The DARPA-funded project High Assurance Cyber-Military System (\href{http://www.darpa.mil/Our_Work/I2O/Programs/High-Assurance_Cyber_Military_Systems_(HACMS).aspx}{HACMS}) aims to produce systems and software with proved reliability and security. It uses the abstraction of nodes and topics to describe the different components and communication channels. A PVS model of these nodes and topics allows to prove security properties. \\

This is a good example of system which requires an implementation and integration of the proven algorithms. For that purpose, a translator PVS to C would be very helpful since most of the ROS systems use the C language.

\subsubsection*{Other translators}

Translating PVS was already done for different purposes.
\begin{itemize}
\item PVS come with a native PVS to Common Lisp translator. This is used to run PVS programs for testing and debugging purposes. Since PVS's API relies heavily on the Common Lisp language, it is very easy to run PVS code within Emacs. The "Ground Evaluator" uses the generated Common Lisp code to evaluate PVS expressions. It provides a more user-friendly interface for the PVS translator by being integrated into Emacs and translating simple Common Lisp expression back to PVS.
\item PVS expressions can also be translated to Yices's specification language syntax. Yices is an efficient SMT solver developed at SRI by Bruno Dutertre. This translation is a way to "plug" the Yices solver into PVS, allowing automated proof of theorems and TCCs.
\item PVS was translated to the Clean language.
\item Lately PVS was also translated to the SMT-LIB language (work in progress) for standardization purposes. This would allow every SMT solver able to process SMT-LIB standard inputs such as Yices 2, to be plugged into PVS for further proof automation.
\end{itemize}


\newpage
\section{Translating PVS}

A translator is a program taking the source code of program $P$ written in the programming language $\mathcal{L}_A$ as an entry and generating the code of an other program $Q$ in the target language $\mathcal{L}_B$ as an output. In our case, $\mathcal{L}_A$ is a subset of PVS and $\mathcal{L}_B$ is the language C. It is expected from a translator to:
\begin{itemize}
\item Never fail if the entry is the code of a valid program in the input language, $\mathcal{L}_A$. However the translator might declare being only able to translate a fragment of the language and restrict its input language. In our case, we expect input programs to be written using the syntax in Figure~\ref{fig:PVSsyntax}, to be parsed and typechecked using PVS without error and finally, we expect that TCCs generated by PVS can be proven.
\item Generate a valid program in the target language $\mathcal{L}_B$. In our case, some of the key requirements are that the generated code can be compiled using the GNU Compiler Collection (\href{https://gcc.gnu.org/}{gcc.gnu.org/}) and never raises a segmentation fault error during its execution.
\item For all entry $x$, $P(x)$ and $Q(x)$ return the same result (correctness). More precisely, since both programs take different data structure as entries, if $x_A$ and $x_B$ have the same mathematical evaluation respectively in the languages $\mathcal{L}_A$ and $\mathcal{L}_B$ then $P(x)$ and $Q(x)$ also have the same mathematical evaluation.
\end{itemize}


\subsection{Translator's architecture}

The translation from PVS \cite{PVS:manuals} to C follows these main steps:
\begin{itemize}
\item Typechecking: The PVS typechecker \cite{PVS:userguide} perform a type analysis on the PVS code to associate a PVS type to each expression. This might generates some proof obligations (TCC). The user of the translator has to make sure that the PVS code can be correctly typechecked and that all TCC can be proven.

\item Lexical and syntactic analysis: The PVS parser transforms PVS \cite{PVS:language} code into a CLOS internal representation. \\

In Figure~\ref{fig:PVSsyntax}, we describe the syntax of the subset of PVS we are currently able to translate to C.
In Figure~\ref{fig:PVS-CLOS}, we describe the Common Lisp Object System architecture used by PVS to represent them in Common Lisp. Some classes and some slots in the classes are voluntarily omitted. For a full description of PVS parser representation, refer to \cite{PVS:api}.

\item Translation: The translator flattens all PVS definitions to generates a program in an intermediate language which heavily relies on the use of intermediate variables to store the values of every expression. Besides, this form allows a simpler static analysis. The translation is briefly described in subsection~\ref{subsec:pvssyntax}. The syntax of this language is described Figure~\ref{fig:aux-syntax}.

\item Static analysis: The intermediate language is analyzed and stripped from some of its unnecessary copies and non destructive updates using flow analysis. This analysis inspired from Shankar \cite{shankar02} and Cerny and Shankar's \cite{pavol} previous analysis of PVS is described with more detail in Section~\ref{sec:StaticAnal}.

\item Optimizations: Several simple analysis are performed to determine, for instance, where to declare and free variables as well as the most adapted C types to use. The output is a more complete and closer to C version of the intermediate language. The type translation is described in the subsection~\ref{subsec:pvstypes}. The code generated from that step can be described by the syntax in Figure~\ref{fig:Csyntax}. 

\item Code generation: C code is generated (.c and .h files) and can be compiled using gcc and executed when linked with the garbage collector and the GMP library. The C syntax is described in \cite{huss2004c} and the GMP library reference can be found at \href{https://gmplib.org/manual/}{https://gmplib.org/manual/}.
\end{itemize}



\subsection{Translating PVS type}
\label{subsec:pvstypes}

\subsubsection{PVS type system}
A PVS theory needs to be typechecked using the emacs interface \cl{M-x typecheck} or calling the Lisp function \cl{(tc name-theory)}. This runs the PVS parser on the code and generates CLOS objects to represent it. Then, the PVS typechecker is run on this internal representation of the theory and tries to give a type to all expressions generating TCC when needed.\\

The (simplified) syntax for PVS types is described in Figure~\ref{fig:PVS-types}. PVS allow a base types such as \cl{boolean}s or \cl{number}s. Then more complex types can be defined such as sets, tuples, datatypes or functions with range and values over other types. Types can also be restricted into subtypes using predicates. For example, \cl{integer}s are defined as a subtype of \cl{rational}s with the predicate \cl{integer\_pred}. This way, when an expression is passed to a function ranging over integers, the typechecker generates the TCC "argument must verify the predicate \cl{integer\_pred}". That TCC must then be proven (it is often proven automatically for such simple TCCs). \\

The Figure~\ref{fig:PVS-CLOS-types} describes how PVS type system is represented in CLOS. 


\subsubsection{C types}
The C language \cite{huss2004c} has a few base types to represent bounded integers (\cl{int}, \cl{long}, etc). It allows to define enumerated types, structures containing several fields with different types. The variables with a pointer type have a memory address as a value. They can be used to reference arrays dynamically allocated in the heap.

To represent big integers or rationals, we use the GMP library which introduces a few other types.

\begin{lstlisting}[caption=C types]
    // integer and floating point types
    [unsigned] char, int, long, double
    type*         //arrays
    char*         // strings
    struct types  // structures with fields
    enum types    // enumerated types
    mpz_t, mpq_t  // GMP library
    short int, float, union, size_t // etc...
\end{lstlisting}


\subsubsection{Translation rules}
The translation of PVS types requires a type analysis to decide on the type of a PVS expression.

For instance the translation of the PVS \cl{int} type can be done using the \cl{int}, \cl{unsigned long} or \cl{mpz\_t} C types. In that case, we need to study the range of the expression to decide which types are best to represent it. Then we take the context in which the expression appears to decide. For instance when a variable \cl{x} is typed with a subtype that bounds the range of the values \cl{x} can take, we can safely represent it with a C bounded type.
\begin{lstlisting}
incr(x:below(10)):int = x+1
int incr(int x) { return x+1; }
\end{lstlisting}
In that case, we not only decide to represent \cl{x} with an integer but also the expressions \cl{1} and \cl{x+1} as well as the return value of \cl{incr}. This requires an range analysis to realize that $\cl{1} \in [1;1]$ and $\cl{x+1} \in [1;10]$ can both be represented by the \cl{int} type.\\

When such optimizations are impossible we have to rely on bigger base types or use the GMP types which can generate a much less readable code (see Section~\ref{sec:Concl}, Figure~\ref{fig:exGMP}) and often requires a few conversions. \\

We decide represent functions ranging over integer bounded type with index starting at 0 with arrays and other with closures. It is the responsibility of the user who needs an efficient representation with C arrays to use such types.\\

We describe here a few translation rules
\begin{figure}[!ht]
\begin{tabular}{|l|l|}
\hline
\cl{subrange(a, b)} &
\begin{lstlisting}
int            // if small enough
unsigned long  // if too big or needed for function call
mpz_t          // else
\end{lstlisting} \\ \hline
\cl{int} &
\begin{lstlisting}
mpz_t
\end{lstlisting} \\ \hline
\cl{rat} &
\begin{lstlisting}
mpq_t
\end{lstlisting} \\ \hline
\cl{[below(a) -> Type]} &
\begin{lstlisting}
(Ctype)*
\end{lstlisting} \\ \hline
\cl{T : TYPE = [\# $x_i$ : $t_i$ \#]}  &
\begin{lstlisting}
struct CT {
   ...
   Ct_i x_i;
   ...
}; // These types must be declared
\end{lstlisting} \\ \hline
\cl{[Range -> Domain]} & C closure parameterized by the \cl{Domain} return type.\\ \hline
\end{tabular}
\caption{Translation rules for PVS types}
\end{figure}


\subsection{Translating PVS syntax}
\label{subsec:pvssyntax}

Whereas PVS syntax relies on expressions built from other expressions in a tree-like structure, the C language relies on a instructions, memory allocation and the use of variables. Even though some simple PVS expression (for instance \cl{2*(x+y)} for \cl{x} and \cl{y} typed as small integers) can be directly translated to C expressions (\cl{2*(x+y)} with \cl{x} and \cl{y} typed as \cl{int}), most of the time to represent a PVS expression in the C language, we need to build it and store it into a variable. For instance \cl{X[0] + 1} should be translated to
\begin{lstlisting}
mpz_t aux = X[0];
mpz_t one;
mpz_init_set_ui(one, (unsigned long int) 1);
mpz_t res;
mpz_init( res );
mpz_add(res, aux, one);
mpz_clear(aux);
mpz_clear(one);
[...]  // Use res here, its value represent X[0] + 1
mpz_clear(res);
\end{lstlisting}
So to obtain a C expression (variable) representing a PVS expression, we usually need a few instructions to initialize it, the variable (or C expression) itself and a few instructions to destroy the variables created. \\

Typically, an expression $e$ is going to be translated into a tuple of four elements $(T,E,I,D)$, where $T$ represents a C type used to describe the expression, $E$ is a simple expression (a variable, a function call, an access to an array, etc), $I$ is a list of instructions to be executed prior to using $E$, the initialization of the expression. Finally $D$ is a list of instructions to be executed when $E$ isn't needed anymore, the destruction of $E$.


\subsubsection*{Main functions}

We first define a function $T$ to translate an expression $e$.
$$ T(e) = ( \ T^t(e) \ , \ T^n(e) \ , \ T^i(e) \ , \ T^d(e) \ ) $$
where $T^n(e)$ might be a hole: ?. In that case, the instructions $T^i(e)$ and $T^d(e)$ might contain occurrences of the hole.
From that function, we define a similar function
$$ R(e, t) = ( \ t \ , \ T^n(e) \ , \ T^i(e) \ , \ T^d(e) \ ) $$
which decides the type of the C expression returned. This function uses the result of $T$ and may perform conversions to make sure its result has the expected type. Also the result of this function is never a hole. Finally the function
$$ S(e, t, n) = ( \ t \ , \ n \ , \ T^i(e) \ , \ T^d(e) \ ) $$
imposes the C expression to be a variable with the given name and type.

\subsubsection*{Example}

As an example, we describe here what would be the trace of the execution of the translator on the following PVS expression.
$$ E := \cl{lambda(x:below(10)):x WITH (1) := 5} $$

We suppose that the static analysis decides to make the update destructively. The output would be, before the optimization:

\begin{lstlisting}
   mpz_t* A;
   A = malloc( 10 * sizeof(mpz_t) );
   for (i=0; i<10; i++) {  mpz_init(A[i]);  }
   for (x=0; x<10; x++) {
      mpz_init(A[i]);
      mpz_set_ui( A[x], x );
   }
   int N;
   N = 1;
   mpz_t R;
   mpz_init(R);
   mpz_set_ui(R, 5);
   mpz_set(A[n], R);
   mpz_clear(R);
    [...] // use A here
   for(x=0; x<10; x++)  mpz_clear(A[i]);
   free(A);
\end{lstlisting}

Figure~\ref{fig:exTrans} is the description of the trace of the translator.

\begin{figure}
\begin{tabular}{|p{3.2cm}|p{4.5cm}|p{3.9cm}|p{1.2cm}|p{2.6cm}|}
\hline
To compute & Needed & I & [T] E & D  \\ \hline
$ R(E, \cl{mpz\_t*})$ &
$S_1 := S(\cl{$\lambda$x.x}, \cl{mpz\_t*}, \cl{A})$ \newline
$S_2 := S(\cl{1}, \cl{int}, \cl{N})$ \newline
$S_3 := S(\cl{5}, \cl{mpz\_t}, \cl{R})$ &
\cl{mpz\_t*A;} \ $S_1^i$ \newline
\cl{int N;} \ $S_2^i$ \newline
\cl{mpz\_t R;} \ $S_3^i$ \newline
\cl{mpz\_set(A[N],R);} \newline
$S_1^d$ $S_2^d$ $S_3^d$
& \cl{A} & $S_1^d$ \\ \hline

$S(\cl{1}, \cl{int}, \cl{N})$ &
$R_1 := R(\cl{1}, \cl{int})$ &
$R_1^i$ \ \ \cl{N = $R_1^e$;} \ \ $R_1^d$ &
\cl{N} & \\ \hline

$R(\cl{1}, \cl{int})$ &
$T_1 := T(\cl{1})$ &
$T_1^i$ & $T_1^e$ & $T_1^d$ \\ \hline

$T(\cl{1})$ & & & \cl{int 1} & \\ \hline

$S(\cl{5}, \cl{mpz\_t}, \cl{R})$ &
$T_1 := T(\cl{5})$ &
$T_1^i$ \newline
\cl{mpz\_init(R);} \newline
\cl{mpz\_set\_ui(R, $T_1^e$);} \newline
$T_1^d$
& \cl{R} &
\cl{mpz\_clear(R);} \\ \hline

$T(\cl{5})$ & & & \cl{int 5} & \\ \hline

$S(\lambda\cl{x}.\cl{x},\cl{mpz\_t*},\cl{A})$ &
$S_x := S(\cl{x}, \cl{mpz\_t}, \cl{A[x]})$ &
\cl{A = malloc(10$...$);} \newline
\cl{for(x=0$...$10)} \newline
\phantom{tes } $S_x^i$
& \cl{R} &
\cl{for(x=0$...$10)} \newline
\phantom{tes } $S_x^d$ \newline
\cl{free(A);} \\ \hline

$S(\cl{x},\cl{mpz\_t},\cl{A[x]})$ & $T_1 := T(x)$ & 
\cl{mpz\_init(A[x]);} \newline
$T_1^i$ \newline
\cl{mpz\_set\_ui(A[x],} \newline
\phantom{mmmmmmmmi} \cl{$T_1^e$); }
& \cl{A[x]} &
$T_1^d$ \newline
\cl{mpz\_clear(} \newline 
\phantom{mmmi} \cl{A[x]);}
 \\ \hline

$T(x)$ & & & \cl{int x} & \\ \hline

\end{tabular}
\caption{Example of the translator's execution trace}
\label{fig:exTrans}
\end{figure}







\subsection{Optimization of the intermediate languages}

In order to perform a few analysis, do not translate PVS directly to C but use two intermediate languages instead.
\begin{enumerate}
\item The first of these languages, which syntax is described Figure~\ref{fig:aux-syntax}, is meant to be simple, close enough to C so that optimization performed on it directly translate to C optimization and expressive enough to represent the whole subset of PVS we are interested in. \\

On that language, we perform the analysis consisting in replacing non destructive updates with destructive updates as often as possible. The algorithm is described in Section~\ref{sec:UpdateExpr} and the analysis itself is described in Section~\ref{sec:StaticAnal}.

\item The second language is very close to C but allows to manipulate the code easily and perform a few other optimizations.
\begin{itemize}
\item Determining the adapted C type (especially for integers and function types) to represent variables and adding call to conversion function when necessary.
\item Detecting PVS primitive function calls and the adapted C function to call.
\item Declaring the structures needed.
\item Optimizing the position of declaration and destruction of pointer variables.
\end{itemize}
\end{enumerate}


\newpage
\section{Update expressions}
\label{sec:UpdateExpr}

It is a complicated problem to decide while compiling a functional language whether an update expression should be translated into a destructive or non destructive update in the target imperative language.\\

PVS update expressions are represented in CLOS as \texttt{update-expr} objects
$$ E := \cl{ $T$ with [ ($e1$) := $e2$ ] } $$
where $T$ is an expression typed as a function and therefore might be represented in C as an array (if domain type is \cl{below($n$)}.
We want to know if we can update $T$ in place to obtain a C object representing $E$ or if we have to make a copy of $T$ and update the copy.\\

We discuss here a few solutions to this problem and describe how they are or could have been implemented in the translator.

\subsection{Pointer counting}

Several systems rely on a reference counting garbage collectors. This family of garbage collectors has many advantages \cite{jonesgarbage}. Along with its simplicity and the instantaneity of garbage identification, the one we are interested in is the possibility to determine when a local variable is the only pointer to a complex data structure. In that case, at the cost of a simple test, we can safely avoid copies and perform destructive updates since we are sure no other variables elsewhere in the code is going to be affected by this in place update. We however need to make sure the variable we are updating itself is never used later.

\begin{figure}[!ht]
\begin{tabular}{|p{3.6cm}|p{12.5cm}|}
\hline
\begin{lstlisting}
T* a =
  malloc(10 *
    sizeof(int));
\end{lstlisting} & \begin{lstlisting}
T* a = (T*) GC_malloc(10 * sizeof(int));
\end{lstlisting}
All memory allocation in the heap are handled by the GC's \cl{GC\_malloc} to make sure every new reference on the heap is in the reference table and has a pointer counter associated to it.
\\ \hline
\begin{lstlisting}
T* a = b;
\end{lstlisting} & \begin{lstlisting}
T* a = (T*) GC( b );
\end{lstlisting}
The reference count on \cl{b} is incremented with \cl{GC} to represent that the local variable \cl{a} now also points to the structure \cl{b} points to.\\ \hline
\begin{lstlisting}
T* f(T* a) {
  T* b = a;
  T* c = b;
  return c;
}
\end{lstlisting} & \begin{lstlisting}
T* f(T* a) {
  T* b = (T*) GC( a );
  T* c = (T*) GC( b );
  GC_free(b);
  GC_free(a);
  return c;
}
\end{lstlisting}
The \cl{GC\_free} instruction will decrement the reference counter of its argument and might free it if this counter is now 0. We use it to decrement the pointer of all local pointers (including arguments) before they are deallocated from the stack. However we do not decrement the return variable since we don't want it to be freed (dangling pointer risk). \\ \hline
\begin{lstlisting}
t[0] = b;
\end{lstlisting} & \begin{lstlisting}
GC_free( t[0] );
t[0] = (T*) GC( b );
\end{lstlisting}
This time, we also make sure the reference counter of \cl{t[0]} is decremented and \cl{t[0]} has a chance to be freed if nothing else points to it.\\ \hline
\begin{lstlisting}
{
  T** t = a;
  [...]
}
\end{lstlisting} & \begin{lstlisting}
{  T** t = GC( a );
   [...]
   GC_free( t );
   if (GC_count(t) == 1)
     for (i = 0; i < ...; i++)
       GC_free( t[i] );
   GC_free( t );   }
\end{lstlisting}
When an array of arrays is freed, we need to make sure we decrement everything it was pointing to. \\ \hline
\end{tabular}
\caption{GC instructions}
\label{fig:GCinstr}
\end{figure}

The idea is to keep track of the number of pointers pointing to an array or a struct. We can detect, by checking the pointer counter, if an array is referenced in several portions of the code (nested reference in other data structure, local variable in calling function, ...) and then perform all updates non destructively to avoid inconsistency.\\

We implement a very simple "Reference Counting Garbage Collector" as described in \cite{jonesgarbage} and integrate it to the C code generated according to the rules described Figure~\ref{fig:GCinstr}. \\

The GC consists in a hashtable of pointer counters that we maintain during the execution of the code. Each pointer to data allocated on the heap is a key in the hashtable to which we associate an int counter as value. We then make sure that all memory allocations in the code make a call to the GC to "declare" the new memory. The GC we implemented is described Figure~\ref{fig:GC.h}.



\begin{figure}[!ht]
\begin{lstlisting}
struct entry_s {
   void*  pointer;
   int    counter;
   struct entry_s *tl;
};
typedef struct entry_s* entry;

struct hashtable_s {
   int    size;
   entry* table;	
}; 
typedef struct hashtable_s* hashtable;

hashtable ht_create  ( int size );
int       ht_hashfunc( hashtable hashtable, void* pointer );
entry     ht_newentry( void* pointer );

hashtable GC_hashtable;
void      GC_start();
void      GC_quit();
entry     GC_get_entry( void* pointer );
void      GC_add_entry( entry e);
void      GC_new( void* pointer );
void*     GC( void* pointer );
int       GC_count( void* pointer );
void*     GC_malloc( int length, int size );
int       GC_free(void* pointer);
\end{lstlisting}
\caption{Garbage collector C header file: GC.h}
\label{fig:GC.h}
\end{figure}



\subsubsection{How to use it}

The garbage collector must be used for every manipulation of pointers to memory which was dynamically allocated on the heap. This occurs typically when representing PVS arrays or data structure. \\

When \cl{A} points to an array (or \cl{struct}) we want to update destructively, we first have to check if the pointer counter on \cl{A} is 1. If so, we can update in place because only the local variable \cl{A} points to the array.\\

However, we need to be careful.
$$ \cl{g(A:Array) : int = f(A, A WITH [(0) := 3] )}$$
should not be translated to
\begin{lstlisting}
g(int* A) {
  A[0] = 3;
  return f(A, A);
}
\end{lstlisting}
for (at least) two reasons:
\begin{itemize}
\item The variable \cl{A} is updated destructively but it is later used as a reference to the previous value of the array.
\item \cl{f} is given twice a pointer to the same data structure. Its reference counter should be incremented.
\end{itemize}

Below are a few rules a good use of the GC should follow (see Figure~\ref{fig:exampleGC}).
\begin{enumerate}
\item All dynamically allocated memory on the stack should be done using the GC.
\item All function is responsible for freeing all its arguments. Indeed, the local variable implicitly created to represent the argument is itself a pointer to the structure.
\item All argument passed to a function must have its counter incremented via the GC.
\end{enumerate}
However a few optimizations are possible. For instance if a variable has its counter incremented before being passed to a function and is then freed right after, then it can be directly passed and rely on the function call to free it.
\begin{figure}[!ht]
\begin{lstlisting}
void main() {
   GC_start();
   
   int* A = GC_malloc(10, sizeof(int) );  // Pointer counter of A = 1
   int i;
   for(i = 0; i < 10; i++)  // Initialisation of A
      A[i] = i;             // Here A = lambda(x):x
   int* B = g( GC(A) );     // We need A further, we make sure that g knows
   int* C = A;              // main still has a pointer to A
   printf("Pointers to C = %d", GC_count(C) ); // equal to 2
   GC_free(B); // Frees B
   GC_free(C); // Only decrement the counter of C
   GC_free(A); // Frees A (and C)
   GC_quit();
}

g(int* A) {
  int* arg1 = GC(A);           // A and arg1 now both point to the array
  int* arg2;
  if (GC(A) == 1)             // This is false
     arg2 = GC( A );
  else {                      // The update must be done non destructively
     arg2 = GC_malloc( 10, sizeof(int) );
     int i;
     for(i =0; i < 10; i++)
         arg2[i] = A[i];
  }  
  arg2[0] = 3;
  GC_free(A);                 // A is never used afterwards, we free it here
                              //(this requires an analysis of the C code)
  int* result = f(arg1, arg2);// A function is responsible for freeing its arguments
                              // (this is why we don't free arg1 and arg2)
  return result;
}
\end{lstlisting}
\caption{Example of the use of the GC}
\label{fig:exampleGC}
\end{figure}

But again, we are lucky here that \cl{A} is the first argument of \cl{f}. If the updated \cl{A} were the first arguments, the update would have been done destructively.\\

This is why the GC alone is not enough. We need an analysis of the C code to determine whether a variable is going to be used later in the code or not (\safe occurrence, cf \hyperref[Canalysis]{\ref*{Canalysis} Analysis of the intermediate language}).


\subsubsection{Pros and cons}

The use of a garbage collector integrated in the C code seems like a good idea when translating a functional language to C. Using a pointer counting GC allows to dynamically allocate memory on the heap and pass or return such dynamically allocated object without worrying about where and when they are going to be freed.\\

We however need an analysis of the C code for several reasons:
\begin{itemize}
\item To \cl{GC\_free} variable as soon as they are not needed anymore. Otherwise copies that could be avoided are performed because an other (useless) pointer still points to the structure we're interested in.
\begin{lstlisting}
int* B = GC( A );
update(B, 0, 1); // Can't be done destructively because A also points to
GC_free(A);      // the same data as B
f( GC(B) );      // f is given a variable with a reference counter of 2.
GC_free( B );    // It might not be able to perform some update destructively
\end{lstlisting}
Should be
\begin{lstlisting}
int* B = A;
update(B, 0, 1);  // Can now be done destructively
f( B );           // f is given a variable with a reference counter of 1.
\end{lstlisting}
\item Every update require now tests and calls to hashtable functions. This is a small cost compared to the copying it may allow to avoid but no so small compared to a single in place update that could be decided by a code analysis.
\item Besides, the code gets much bigger since every update or copy requires the code to both destructive and non destructive operation and the if statement to decide which one to use. For instance, passing arguments to a function adds quite some code
\begin{center}
\begin{tabular}{|c||l|}
\hline
GC use & Static analysis optimization  \\ \hline
\begin{minipage}{10cm}
\begin{lstlisting}
int* f(int* arg) {
   int* result;
   if ( GC_count(arg) == 1)
      result = GC( arg );
   else {
      result = GC_malloc(10, sizeof(int));
      int i;
      for(i = 0; i < 10; i++)
         result[i] = GC( arg[i] );
   }
   GC_free(arg);
   result[0] = 3;
   return result;
}
\end{lstlisting}
\end{minipage}
&
\begin{lstlisting}
int* f(int* arg) {
   arg[0] = 3;
   return arg;
}
\end{lstlisting} \\ \hline
\end{tabular}
\end{center}

\end{itemize}




\subsection{Using a more adapted data structure}

The Lisp code generated by PVS and used for example by the ground evaluator to compute PVS expressions represents PVS arrays with a more complex data structure than a simple array. It basically consists in an array and a replacement list. Every time an update on \cl{(A, l)} is performed, the result is a pointer to the same array \cl{A} and a replacement list with an extra term.
\begin{eqnarray*}
\cl{T} &\Longrightarrow& \cl{(A, l)} \\
\cl{T[(0) := 0]}&\Longrightarrow& \cl{(A, (0:=0) :: l)}
\end{eqnarray*}
We could implement this data structure with a similar C structure. For example :
\begin{center}
\begin{tabular}{ccc}
\begin{lstlisting}
struct array_int {
   int *data;
   r_int_list* replacement_list;
};
\end{lstlisting}
&  \hspace{2cm} &
\begin{lstlisting}
struct r_int_list {
   int key;
   int value;
   r_list* tl;
};
\end{lstlisting}
\end{tabular}
\end{center}
When the replacement list becomes too long (longer than $\tau(n)$), we create a new array \cl{A'} by applying the replacement terms to a copy of \cl{A} and we return \cl{(A', nil)}. The hope is that by the time we need to perform this copy, nothing else points to the old array so that it is garbage collected immediately. The trade off can be summarized with the worst case complexities:

\begin{center}
\begin{tabular}{|l|l|p{10cm}|}
\hline
 & Copied array & New data structure \\ \hline
Update time & $O(n)$ & $O(n)$ (if copying is needed) but most of the time $O(1)$.  \\ \hline
Update space & $O(n)$ & $O(n)$ (if copying is needed and the old array is not garbage collected) but most of the time $O(1)$. \\ \hline
Access time & $O(1)$ & $O(\tau(n))$ since we need to read the replacement list. \\ \hline
\end{tabular}
\end{center}
Best case scenario, all arrays are always immediately garbage collected after an update and we get these mean complexities
\begin{center}
\begin{tabular}{|l|l|p{4.8cm}|p{4.8cm}|}
\hline
 & Copied array & New data structure & Destructive update \\ \hline
Update time & $O(n)$ & $O(n / \tau(n) )$ & $O(1)$  \\ \hline
Update space & $O(n)$ & $O(1)$ & $0$\\ \hline
Access time & $O(1)$ & $O(\tau(n))$ & $O(1)$ \\ \hline
\end{tabular}
\end{center}

We have the following issues:
\begin{itemize}
\item This adds some extra code both to implement the new data structures and algorithms and to use them.
\item This adds some extra run time for reading accesses which require reading the whole replacement list.
\item This relies a lot on the GC.
\end{itemize}


\subsection{Flow analysis on the PVS code}

An other optimization would be to perform an analysis on the PVS expressions. Shankar \cite{shankar02} and later Cerny and Shankar's \cite{pavol} suggest several analysis based on flow analysis that allow to replace PVS non destructive updates with destructive updates.\\

These analysis require the definition of two versions of each function. A safe version that can always be called and never  performs any destructive update and an other "destructive" version that can only be called under certain conditions on the arguments. However thanks to these conditions, the body of that destructive version is allowed to perform safe destructive update and may call destructive versions of functions.\\

We didn't implement these analysis into the translator but they inspired the static analysis on the intermediate language described next.


\subsection{Analysis of the intermediate language}
\label{Canalysis}

One of the solutions we decided to implement to solve the update problem  consists in an analysis on the intermediate language before the optimization and generation of the actual output C code.\\

We also use two different versions of a PVS function called $f$ and $f^d$. Our analysis differs from Shankar and Shankar and Cerny's previous work in (at least) the following:
\begin{itemize}
\item The non destructive version of a function is also optimized and might have some destructive updates or function calls.
\item The destructive function does not have all its function call destructive.
\end{itemize}

The analysis is explained in details in Section~\ref{sec:StaticAnal}. The analysis we implemented basically relies on over approximations of the sets of critical and free variables in a context.

\subsubsection*{The flags}

We define three flags:
\begin{itemize}
\item \bang means that the variable is the only pointer to the structure or array it points to. For instance if we have \cl{f(A:Arr):Arr = A WITH [(0) := 0]} then when \cl{f} is called in
$$ \cl{let A = lambda(x:int):x in let B = f(A) in B(0)} $$
we know that \cl{f} can update \cl{A} in place because only $A$ itself points to the newly created array and $A$ is not needed later in the code. We call the following (destructive) version of \cl{f}.
\begin{lstlisting}
int* f(int* A) {
  A[0] = 0;
  return A;
}
\end{lstlisting}

\item \safe means that an occurrence of a variable is the last occurrence of that variable in the code. We need this flag to avoid updating destructively variables that appears later in the code. In the previous example, if we encounter
$$ \cl{let A = lambda(x:int):x in let B = f(A) in B(0) + A(0) }$$
we know we can't update \cl{A} destructively and we call instead a non-destructive version of \cl{f}:
\begin{lstlisting}
int* f(int* A) {
  int* res = malloc(...);
  for( i ...) res[i] = A[i];
  res[0] = 0;
  return res;
}
\end{lstlisting}

\item \dupl means that this expression may find itself nested in the result of the current function. For instance the identity function, \cl{id(A:Arr):Arr = A}, has its argument flagged \dupl. Therefore when \cl{id} is called we know that the result contains a pointer to its argument.
\begin{lstlisting}
...
int* A = malloc(...);
[ init A somehow ]
int* B = id(A);
\\ From now on B and A point to the same array
\\ For instance, A should probably not be modified in place
...
\end{lstlisting}
This flag detects the arguments whose reference can be trapped in the result of a function call. This allows to properly maintain the \bang flag.
\end{itemize}




We want to ensure the following properties on the flags.\\
\newline

\safe flag:
\begin{itemize}
  \item Only a single occurrence of a variable may be flagged \safe.
  \item An occurrence of a variable $x$ is flagged \safe in an instruction iif $x$ occurs once in the instruction and never after.
\end{itemize}

\dupl flag
\begin{itemize}
  \item Only expressions and arguments can be flagged \dupl.
  \item If a variable is once flagged \dupl, then if it is an argument, this argument is also flagged \dupl.
\end{itemize}

\bang flag:
\begin{itemize}
  \item Only functions and variables with struct or array (return) types can be flagged \bang.
  \item Arguments of a non destructive function are never flagged \bang.
  \item A function is flagged \bang iif its return variable is flagged \bang.
  \item A variable may be flagged bang if it is created with a \cl{copy}, \cl{init\_array}, \cl{init\_record} or is the result of a call to a function flagged \bang.\\
It may not be flagged \bang if it is the result of a call to a function not flagged \bang.
  \item A call to a destructive function \cl{f\_d( $a_i$, $b_j$, $c_k$ )} (where $a_i$ are flagged \bang and $b_j$ are flagged \dupl and $c_k$ are not flagged) may only occurs if the following conditions on the arguments passed $( A_i, B_j, C_k )$ are met:
\begin{itemize}
   \item All $A_i$ are either calls to functions flagged \bang or variables flagged \bang and \safe.
   \item All $B_j$ are either calls to functions or variables flagged \safe or not flagged \bang.
   \item If the function call is flagged \dupl, then all $B_j$ are also flagged \dupl.
\end{itemize}
\end{itemize}


\subsubsection*{Algorithm}

Each PVS function is translated into two different C functions:
\begin{itemize}
\item A "cautious" non destructive version whose arguments are never \bang and therefore never modifies the arguments in place, always making copies when necessary. This doesn't mean this function can't make destructive update. For instance locally created arrays (using \cl{init\_array}) will be flagged \bang and might be destructively updated, should the conditions be met.
\item A destructive version which requires as many arguments as possible to be \bang and tries to do destructive updates as often as possible. This function only requires \bang arguments if it uses it destructively though.
\end{itemize}
The main difference between the two is that a non destructive function's arguments are never flagged \bang. See Listing~\ref{lst:ex2versions} for an example.



\begin{lstlisting}[numbers=left,caption={Example of the two different versions of a C function generated (stripped from GC instructions)}, label={lst:ex2versions}]
f(int* A, int* B) {         // A and B are both flagged duplicated
   if (A[0] == 0) {
      return B;
   } else {
      int* arg1 = copy(B);  // arg1 is flagged mutable and duplicated
      arg1[0] = arg1[0] - 1;
      f(arg1, A); // Both these occurrences of arg1 and A are flagged safe
   }
}

f_d(int* A, int* B) {  // A and B are both flagged mutable and duplicated
   if (A[0] == 0) {
      return B;
   } else {
      int* arg1 = B;    // No need to copy since B is mutable
                        // and never occurs afterwards
      arg1[0] = arg1[0] - 1;
      f_d(arg1, A);     // we can call f_d since the requirements are met:
   }                    //    both arg1 and A are flagged mutable
}
\end{lstlisting}

The algorithm is described Figure~\ref{fig:algo}. It terminates since \dupl the flags can only be added, \bang flags are removed for good and \safe flags can only be removed.

\begin{figure}[!ht]
\begin{itemize}
\item Create the two versions of each function initialized with the same body containing no destructive update or function call.

\item For each function:
\begin{itemize}
\item Flag all arguments \bang in the destructive version only.

\item Perform several passes \bang analysis.\\
We flag a variable $x$ when $x$ is initialized with.
  \begin{itemize}
    \item A newly created array (\cl{array(x)}).
    \item An update (destructive or not).
    \item A call to a function with a \bang return type.
  \end{itemize}
We remove the \bang flag definitely of a variable $x$ when
  \begin{itemize}
    \item $x$ never occurs destructively
    \item $x$ gets duplicated before its last occurrence
  \end{itemize}
This allows to make sure the \bang properties are verified.

\item Perform a backward pass \dupl analysis.\\
If $x$ is flagged \dupl, then if $x$ is set to...
  \begin{itemize}
    \item ... a function call, flag \dupl all variables passed as \dupl arguments.
    \item ... an other expression, flag \dupl all the active variables of that expression.
  \end{itemize}

\item Perform a \safe analysis to flag all variables \safe if they fulfill the rules described above.

\item Modify the code if the flags allow it according to the rules defined in the Annex~\ref{Rules}. This may consists in renaming variable, changing the version of a function called, 

\item Redo the two previous steps until stabilization.
\end{itemize}
\end{itemize}
\caption{Algorithm}
\label{fig:algo}
\end{figure}


\newpage
\subsubsection*{Link with the analysis}

To connect with the analysis Section~\ref{sec:StaticAnal}, we could say that
\begin{itemize}
\item A occurrence of a variable $x$ is flagged \safe when this variable is not live in the context of that occurrence.

\item The variables flagged \bang correspond to the variables that could be critical variables in a context. \\

If $f(f_i) := U\ucont{\cl{set(}x\cl{, }a\cl{); }e}$, the variable $x$ is flagged \bang when all $Ov(a)$ are flagged \bang as well and \safe. This means all the critical variables of $x$ are neither live in $U$ nor free in $e$.\\
Then if $x$ is used in a way such that it could get trapped into an other structure (active arguments of a function call, unsafe destructive update, etc) then it loses its \bang attribute.

\item Arguments $f_i$ are flagged \bang, when $f_i \in BA(f)$. This is why we ensure no arguments in non destructive versions of functions are flagged \bang.

\item An expression $a$ is flagged \dupl when $Av(a) \subset Av(e)$. We are only interested in the arguments $f_i$ of $f$ that are flagged \dupl though.
\end{itemize}






\subsection{Implemented solution}

We decided to implement a reference counting GC that we use to detect on the fly if a variable can be safely updated. However the main optimization is the analysis performed on the intermediate language. \\

This analysis, however is far from perfect. For instance:
\begin{itemize}
\item If a function is called but requires its two argument to be \bang and only the first is. Then the non-destructive version is called and the first argument gets copied even though it was \bang.
We would need probably a lot more versions of functions to solve that problem. However an analysis of all the function calls that are made could narrow the number of versions enough to allow their implementation. This would still increase the size of the code a lot, though.

\item We never perform a destructive update on \cl{$T$[i]} which is never flagged \bang ($X^*$ variables are not handled). Our analysis is too simple to tell if \cl{$T$[i]} is \bang or not.\\

To prevent that, we also perform GC checks when a safe update occurs. However a more complete implementation of the analysis Section~\ref{Canalysis} could probably solve a lot of these cases.
\end{itemize}


\newpage
\section{Static analysis of the intermediate language}
\label{sec:StaticAnal}

We describe here the static analysis of the intermediate language (which syntax is defined in Figure~\ref{fig:aux-syntax}) implemented in the translator.

\begin{figure}[!ht]
\input{includes/aux-expr}
\caption{Syntax of the intermediate language}
\end{figure}

We assume a few properties on valid programs:
\begin{enumerate}
\item The \cl{set} instruction is a declaration and an assignment of a variable to a value at the same time. If an expression contains two \cl{set} of the same variable, the second \cl{set} will override the first definition. We assume then that a variable is never \cl{set} twice in the same expression.
\item The only free variables in the body of a function declaration are the arguments of that function.
\end{enumerate}

Besides we assume these properties on programs generated by the translator:
\begin{enumerate}
\item No destructive update is used to represent PVS updates (before the analysis).
\item 
\end{enumerate}

We first define the semantics of the language using a small-steps operational semantics. Then we define a few operators on the language and exhibit some properties.
Finally we describe an algorithm to replace non destructive updates with destructive updates under certain conditions and prove that there is a bisimulation between programs before and after applying this algorithm. This proves that the execution of the program is not disturbed by the replacements and thus the correctness of the algorithm.



\subsection{Operational semantic}

A \emph{value} is either an integer $n \in \N$, a reference $r \in R$ representing an array (or pointer) or a function id $f \in F$ . The metavariable $v$ ranges over the set of all values: $V := \N \cup R \cup F$.\\

An \emph{evaluation context} (sometimes simply called \emph{context}) $E$ is an expression with an occurrence of a hole $\econt{}$. A context  and is of one of the forms
\begin{enumerate}
\itemsep-0.2em
\item $\econt{}$
\item $\cl{set(} x \cl{, } \econt{} \cl{); } e$
\item $\cl{pop(} \econt{} \cl{)}$
\item $E_1\econt{E_2}$ \ \ , where $E_1$ and $E_2$ are evaluation contexts.
\end{enumerate}
A \emph{redex} is an expression of the following form

\begin{tabular}{p{4.8cm}p{6.8cm}p{4cm}}
\begin{enumerate}
\itemsep-0.2em
\item $x$
\item $X[y]$
\item $\cl{if (} x \cl{) } a \cl{ else } b $
\item $\cl{array(} x \cl{)}$
\end{enumerate} &
\begin{enumerate}
\setcounter{enumi}{4}
\itemsep-0.2em
\item $X\cl{[(} x \cl{) := } y \cl{]}$
\item $X\cl{[(} x \cl{) <- } y \cl{]}$
\item $\cl{lambda(}  f \cl{, } m \cl{, } x_1 \cl{, } ... \cl{, } x_m \cl{)}$
\item $y\cl{(} x_1 \cl{, } ... \cl{, } x_n \cl{)}$
\end{enumerate} &
\begin{enumerate}
\setcounter{enumi}{8}
\itemsep-0.2em
\item $f\cl{(} x_1 \cl{, } ... \cl{, } x_n \cl{)}$
\item $p\cl{(} x_1 \cl{, } ... \cl{, } x_n \cl{)}$
\item $\cl{set(} x \cl{, } v \cl{); } e$
\item $\cl{pop( } v \cl{)}$
\end{enumerate}
\end{tabular}


We define a \emph{local environment}, $s_i$, as a function ranging over the set $N$ of all variable names with values in $V$.\\
The \emph{stack state}, $s$, is a series of local environments: $s = (s_0, ... , s_n)$.\\
We call $[]$ the empty function and if $s_i$ is a local environment ranging over the variables $U$, we write $s_i \uplus (x \mapsto v)$ the function ranging over $U \cup \{x\}$ mapping $x$ to $v$ and $y$ to $s_i(y)$ for $y \neq x$. For $s = (s_0, ... s_n)$ a stack state, we write $s \uplus (x \mapsto v) := \left( s_0 \uplus (x \mapsto v), s_1, ... , s_n \right)$. We also define $s(x)$ as $s_i(x)$ where $\forall j < i, s_j(x)$ is not defined and to simplify notations, we call $s' :: s := (s', s_0, ... , s_n)$ and even $s' :: S  := (s' :: s, h)$.

The \emph{heap state} function, $h$ is mapping references $r$ to arrays of values, $V*$.\\

The \emph{store} (or \emph{state}) function, $S$, describing the state of the memory at a certain point in the execution is defined as the couple $(s, h)$.\\
We define $S(x) := s(x)$ and $S(r) := h(r)$.

A program is list of function declarations followed by a closed expression. For each function with id $f$ declared before the evaluation of the expression, we call $f_i$ the arguments of this function (variables) and $[f]$ its body (expression). A function is associated not only an id but also a number when declared. This number is used in lambda terms to refer to a function using a value.

The meta-variable conventions are that $x$ and $y$ range over variables, $X$ ranges over variables typed as arrays $n$ ranges over numbers, $p$ ranges over primitive function symbols, $f$ ranges over defined function symbols, $a$, $b$ and $e$ range over expressions. \\

A \emph{reduction} transforms a pair consisting of a redex and a store. The reductions corresponding to the redexes above are

\begin{enumerate}
\itemsep-0.2em
\item $<x,S> \ \longrightarrow \ < S(x), S> $
\item $<x \cl{[} y \cl{]} , S> \ \longrightarrow \ < h(s(x))(s(y)) , S>$
\item $<\cl{if (} x \cl{) } a \cl{ else } b, S>  \ \longrightarrow \ 
\left\lbrace \begin{array}{ll}
< \cl{pop(}a\cl{)} , [] :: S > & \text{if } s(x) = 0 \\
< \cl{pop(}b\cl{)} , [] :: S > & \text{otherwise}
\end{array} \right. $
\item $<\cl{array(} x \cl{)} , S > \ \longrightarrow \ <r, \left(s, h \uplus \left( r \mapsto (0)_{0 \leq i < s(x)} \right) \right) >$ where $r$ is a fresh pointer.
\item $< X \cl{[(} x \cl{) := } y \cl{]} , S> \ \longrightarrow \ < r, (s, h') >$ where $r$ is a fresh pointer and
$$ h' = h \uplus \left( r \mapsto h( s(X) ) \uplus \left( s(x) \mapsto s(y) \right) \right) $$
\item $< X \cl{[(} x \cl{) <- } y \cl{]} , S> \ \longrightarrow \ < X, (s, h') >$ where
\begin{eqnarray*}
h' &=& h \uplus \left( s(X) \mapsto h( s(X) ) \uplus \left( s(x) \mapsto s(y) \right) \right)
\end{eqnarray*}
\item $< \cl{lambda(} f \cl{, } m \cl{, } x_1 \cl{, } ... \cl{, } x_m \cl{)} , S > \ \longrightarrow \ < r, (s, h') > $ where $r$ is a fresh pointer and
$$h' = h \uplus ( r \mapsto (f, m, s(x_1), ... , s(x_m) ) ) $$
\item $< y\cl{(} x_1 \cl{, } ... \cl{, } x_n \cl{)}, S> \ \longrightarrow \ < \cl{pop(} [f] \cl{)}, s' :: S>$ where $E = h(s(y))$, $f=E(0)$, $m=E(1)$,
$$ s' : \left| \begin{array}{ccl}
\{ f_1, ... , f_{m+n} \} & \rightarrow & V \\
f_i & \mapsto & E(i+1) \ \ \text{ for } i \leq m \\
f_{m+i} & \mapsto & s(x_i) \ \ \text{ for } i \leq n
\end{array} \right. $$
\item $<f\cl{(} x_1, ... , x_n \cl{)} , S> \ \longrightarrow \ < \cl{pop(} [f] \cl{)}, \left( \biguplus_{1 \leq i \leq n} f_i \mapsto s(x_i) \right) :: S > $
\item $< p\cl{(} x \cl{, } y \cl{)}, S> \ \longrightarrow \ < p( s(x) , s(y) ), S>$ for binary operators.
\item $< p\cl{(} x \cl{)}, S> \ \longrightarrow \ < p( s(x) ), S >$ for the unary operator (\cl{not}).
\item $<\cl{set(} x \cl{, } v \cl{); } e, S> \ \longrightarrow \ < \cl{pop(}e\cl{)}, (x \mapsto v) :: S> $
\item $<\cl{pop(} v \cl{)}, ( (s_0, ... , s_n), h) > \ \longrightarrow \ <v, ( (s_1, ... , s_n), h) > $
\end{enumerate}

An evaluation step operates on a pair $<e, S>$ consisting of a closed expression and a store, and is represented as $<e, S> \ \longrightarrow \ <e', S'>$. If $e$ can be decomposed as a $E\econt{a}$ for an evaluation context $E$ and a redex $a$, then a step $<E\econt{a}, S> \ \longrightarrow \ <E\econt{a'}, S'>$ holds if $<a, s> \ \longrightarrow \ <a', s'>$
This is represented by the following rule.
\begin{prooftree}
\AxiomC{$<a, s> \ \longrightarrow \ <a', s'>$}
\UnaryInfC{$<E\econt{a}, s> \ \longrightarrow \ <E\econt{a'}, s'>$}
\end{prooftree}
One of the greatest advantage of using evaluation contexts is that we define the semantics of this language using only this one small-step rule.\\

The reflexive-transitive closure of $\longrightarrow$  is represented $\xrightarrow{*}$.
The computation of a program is defined as the evaluation of its expression $<e, S_0>$ on an empty store: $S_0 := (([]), [])$.
If $<e, S_0)> \xrightarrow{*} <e', S'>$ then we can prove that $e' \in V$ and the result of the computation is then defined as $eval_{h'}(e')$ where $eval_h$ is defined as follow:
$$ eval_h : \left|
\begin{array}{ccl}
V &\longrightarrow & E \\
n &\mapsto& n \in \N \\
r &\mapsto& \left( eval_h(u_i) \right)_{0 \leq i \leq n} \text{ with } (u_i)_{0 \leq i < n} := h(r)
\end{array}
\right. $$

\begin{theorem}
For all $<e, S_0> \ \xrightarrow{*} \ <v, (s,h)>$, $h$ is defined on $R \cap \left( \{v \} \cup Im(s) \cup Im(h) \right)$. All references stored in the stack or in the heap or reduced from an expression are defined in the heap state.
\end{theorem}
\begin{proof}
We proof this theorem by induction on the structure of the code.
\begin{enumerate}
\item Base cases: All redexes generating a fresh pointer (4, 5 and 7) modify the heap state to define it on that new pointer.\\
\item Induction step:
\begin{itemize}
\item References defined in the store are never undefined. If $<e, S> \ \longrightarrow \ <e', S'>$ and $h$ is defined on $r$ then $h'$ is also defined on $r$. This is easily proven since no redex remove a definition in the heap.
\item Whenever a value in the heap or in the store is modified, it is replaced with functions (redex 7), integers (redexes 4 and 7), values from the heap (redexes 2, 5, 6 and 8), values from the stack (redexes 1, 5, 6, 7, 8, 9, 10 and 11) or values reduced from an expression (redexes 12 and 13).
\end{itemize}
\end{enumerate}
\end{proof}


\subsection{Sets of variables}


We define the free variables, $Fv$, of an expression as the set of all variables that occur in that expression. For this study, we are only interested in variables that may refer to an array.\\

We also define the \emph{output} variables, $Ov(e)$, of an expression. This can be understood in three ways:
\begin{itemize}
\item This is the set of all variables that may have their value "trapped" into the expression $e$.
\item It corresponds to all the variables which content might get modified if $e$ gets modified in place.
\item It is the set of all variables which content the pointer corresponding to the evaluation of $e$ may point to.
\end{itemize}

Finally, we define the \emph{active} variables, $Av$, of an expression. In a similar way, this can be understood as:
\begin{itemize}
\item The set of all variables that may contain a reference to the expression $e$.
\item It corresponds to all the variables that could be accessed from the value returned by the expression.
\item It is the set of all variables which evaluation may be a pointer pointing to $e$.
\end{itemize}

If $X$ s a variable, $X^*$ refers to all the references $X$ may point to. It is obvious that if $X \in Av(e)$, then $X^* \in Av(e)$ as well. In that case, we voluntarily omit to mention $X^*$ in the definition of these set below.

\def\arraystretch{1.2}
\begin{center}
\begin{tabular}{|c|@{}c@{}|@{}c@{}|@{}c@{}|}
\hline
Expression & $Ov$ & $Av$ & $Fv$ \\ \hline
$n$ & $\emptyset$ & $\emptyset$ & $\emptyset$ \\ \hline
$X$ & $\{ X \}$ & $\{ X \}$ & $\{ X \}$ \\ \hline
$X\cl{[}x\cl{]}$ & $\{ X^* \}$ & $\{ X^* \}$ & $\{ X \}$ \\ \hline
\begin{minipage}{2cm}
\vspace{0.1cm}
$\cl{if (} x \cl{) } a$ \\
$ \cl{ else } \ \  b$
\vspace{0.1cm}
\end{minipage} & $Ov(a) \cup Ov(b)$ & $Av(a) \cup Av(b)$ & $Fv(a) \cup Fv(b)$ \\ \hline
$\cl{array(} x \cl{)}$ & $\emptyset$ & $\emptyset$ & $\emptyset$ \\ \hline
$X \cl{[(} x \cl{) := } y \cl{]}$ & $ \emptyset $ & $\{ X^*, y \}$ & $\{ X, y \}$ \\ \hline
$X \cl{[(} x \cl{) <- } y \cl{]}$ & $ \{ X \} $ & $\{ X, y \}$ & $\{ X, y \}$ \\ \hline
$\begin{array}{l}
\cl{lambda(}f\cl{, } m \cl{,} \\
\qquad x_1\cl{, }...\cl{, }x_m\cl{)}
\end{array}$ & $\emptyset$ & $\{ x_1, .. , x_m \}$ & $\{ x_1, .. , x_m \}$ \\ \hline
$y(x_1 \cl{, } ... \cl{, } x_n)$ & $\{ x_1, x^*_1, ... , x_n, x^*_n \}$ & $\{ x_1, ... , x_n \}$ & $\{ y, x_1, .. , x_n \}$ \\ \hline
$f(x_1 \cl{, } ... \cl{, } x_n)$  &
$\begin{array}{cl}
& \{x_i | f_i \in Ov([f]) \} \\
\cup & \{ x^*_i | f^*_i \in Ov([f]) \} \end{array}$ &
$\begin{array}{cl}
& \{x_i | f_i \in Av([f]) \} \\
\cup & \{ x^*_i | f^*_i \in Av([f]) \} \end{array}$
& $\{x_1, .. , x_n \}$ \\ \hline
$p(x_1 \cl{, } ... \cl{, } x_n)$ & $\emptyset$ & $\emptyset$ & $\emptyset$ \\ \hline
\begin{minipage}{2cm}
\vspace{0.1cm}
$\cl{set(}x\cl{, }a\cl{);}$ \\
$e$
\vspace{0.1cm}
\end{minipage} &
$\begin{array}{l}
Ov(e) \cup Av(a) - \{ x, x^* \} \\
\qquad \qquad \text{\ \ if }x^* \in Ov(e) \\
Ov(e) \cup Ov(a) - \{ x \} \\
\qquad \qquad \text{\ \ \ if }x \in Ov(e) \\
Ov(e)  \qquad \text{ \ \ \ otherwise}
\end{array}$
&
$\begin{array}{l}
Av(e) \cup Av(a) - \{ x, x^* \} \\
\qquad \text{ \ \ if $x $ or $x^* \in Av(e)$}\\
Av(e) \qquad \qquad \text{otherwise}
\end{array}$
& $Fv(a) \cup Fv(e) - \{ x \} $ \\ \hline
\end{tabular}
\end{center}
\def\arraystretch{1}


\begin{theorem}
For all expression $e$, $Ov(e) \subset Av(e) \subset Fv(e)$.
\end{theorem}
\begin{proof}
Simple induction proof on the expression form.
\end{proof}





\subsection{Update contexts}

The advantage of using contexts is to be able to place critical expressions like updates into a context where the evaluation order is well defined and we can identify expression evaluated before and after the reduction of a critical redex like a function call or a destructive update. These two being the only redexes that can modify the heap store in place.\\

We introduce \emph{update contexts} as an expression with a single occurrence of a hole:
\begin{enumerate}
\itemsep-0.2em
\item $\ucont{}$
\item $\cl{set(} x \cl{, } U \cl{); } e $
\item $\cl{set(} x \cl{, } a \cl{); } U $
\item $ \cl{if (} x \cl{) } U \cl{ else } b $
\item $ \cl{if (} x \cl{) } a \cl{ else } U $
\end{enumerate}

To define which update can be made destructively, we now build a reference graph in a context $U$. We define the pointer analysis of $U$ as $PA(U)$ where $PA(U)(X)$ is the set of all variables $X$ may point to in the context $U$. It is the smallest set containing $PA^0(U)(X)$ and close under $x \in PA(U)(X) \Longrightarrow PA(U)(x) \subset PA(U)(X)$.
\begin{eqnarray*}
PA^0(\ucont{} ) &:& \left| \begin{array}{lcl}
X   & \mapsto & \{ X, X^* \} \\
X^* & \mapsto & \{ X^* \}
\end{array}  \right. \\
PA^0( \cl{set(} x \cl{, } U \cl{); } e ) &:=& PA(U) \\
PA^0( \cl{set(} x \cl{, } a \cl{); } U )(X) &:=& PA^0(U)(X) \cup \left\lbrace \begin{array}{ll}
\{ x, x^* \} & \text{if $X \in Ov(a)$.} \\
\{ x^* \} & \text{if $X \in Av(a)$.} \\
Av(a) & \text{if $x^* \in PA^0(U)(X)$.} \\
\emptyset & \text{otherwise.}
\end{array} \right. \\
PA^0( \cl{if (} x \cl{) } U \cl{ else } b ) &:=& PA^0(U) \\
PA^0( \cl{if (} x \cl{) } a \cl{ else } U ) &:=& PA^0(U) 
\end{eqnarray*}
This will allow us to define the variables live in this context as well as the set of critical variables that could be modified by a destructive update.
\begin{itemize}
\item For $X$ a variable and $U$ a context, the set of critical variables $Cv(U)(X)$ contains all variables that may point to $X$ and all variable that may point to these variables and so on.
$$ Cv(U)(X) := \{ \ y \ | \ X \in PA(U)(y) \ \} = PA(u)^{-1}(\{X \}) $$
\item The set $Lv(U)$ of the variables live in the context $U$ are the variables that could be evaluated after the hole the in the context and the variables that these variables may point to and so on.
\begin{eqnarray*}
Lv^0(\ucont{} ) &:=& \emptyset \\
Lv^0( \cl{set(} x \cl{, } U \cl{); } e ) &:=& Fv(e) \cup Lv^0(U) \\
Lv^0( \cl{set(} x \cl{, } a \cl{); } U )(X) &:=& Lv^0(U) \\
Lv^0( \cl{if (} x \cl{) } U \cl{ else } b ) &:=& Lv^0(U) \\
Lv^0( \cl{if (} x \cl{) } a \cl{ else } U ) &:=& Lv^0(U) \\
Lv(U) &:=& \bigcup_{x\in Lv^0(U)} PA(U)(x)
\end{eqnarray*}
\end{itemize}
%The set $Lv(U)$ of the variables live in the context $U$ are the variables that could be evaluated after the hole the in the context and the variables that these variables may point to and so on. It is defined as the smallest set containing $Lv^0(U)$ an close under 
%$$ PA(U)(Lv(U)) \subset Lv(U) $$
%where $Lv^0(U)$ is defined as
%\begin{eqnarray*}
%Lv^0(\ucont{} ) &:=& \emptyset \\
%Lv^0( \cl{set(} x \cl{, } U \cl{); } e ) &:=& Fv(e) \cup Lv^0(U) \\
%Lv^0( \cl{set(} x \cl{, } a \cl{); } U )(X) &:=& Lv^0(U) \\
%Lv^0( \cl{if (} x \cl{) } U \cl{ else } b ) &:=& Lv^0(U) \\
%Lv^0( \cl{if (} x \cl{) } a \cl{ else } U ) &:=& Lv^0(U)
%\end{eqnarray*}
When we consider turning a non destructive update $X\cl{[(}x\cl{) := } \cl{y} \cl{]}$ in a context $U$ into a destructive update, we want to make sure that critical variables are not live $U$.
$$ Cv(U)(X) \cap Lv(U) = \emptyset $$




\subsection{Analysis}

We consider here a function $f$ which declaration body $e$ doesn't contain any destructive update before the analysis. The reason is that a safe, naive translation from PVS to this language would only perform non destructive updates.

Intuitively, if a function $f\cl{(}f_1\cl{, } ... \cl{, } f_n\cl{) = } e$ contains a non destructive update in a context $e = U\ucont{X\cl{[(}x\cl{) := }y\cl{]}}$. That update can be turned into a destructive update if none of the variables that may be aliased to $X$ are live in the context.
$$ Cv(U)(X) \cap Lv(U) = \emptyset $$
This way all this variables that may point to $X$ are never used after the update. Since they are the only variables whose evaluation is modified by making the update destructive, we can say that this is a safe transformation.\\

The problem is that some of these variables possibly pointing to $X$ might be included in the set of arguments of $f$: $\{f_1, ... , f_n\}$. And we can't assume anything about these variables since we don't have any information regarding the context in which the function $f$ is called.\\

We define the bang analysis $BA(f)$ as the set of all variables that are involved in a destructive update or are destructive arguments in a call to a destructive function:
$$ BA(f) \ \ := \ \ \left( \bigcup_{e = U\ucont{X\cl{[(}x \cl{) <- } y \cl{]} }}  Cv(U)(X) \right) \ \ \cup \ \ \left( \bigcup_{e = U\ucont{g\cl{(} x_1\cl{,} ... \cl{,} x_n \cl{)}}} Cv(U)( \{ x_i | g_i \in BA(g) \}) \right)$$
Basically $BA(f)$ is the set of all critical variables in the evaluation of a function call to $f$.

We define two versions of all function declared. A non destructive version $f$ with body $e_{nd}$ and a destructive version $f^d$ with body $e_d$.
Both new definitions may only differ from the original body $e$ of $f$ in some very specific substitutions: non destructive updates in $e$ may be destructive in $e_{nd}$ and $e_d$ and function calls to a function $g$ may become function calls to $g^d$ with the same arguments in $e_d$ and $e_{nd}$.\\

These functions use two different strategies:
\begin{itemize}
\item The second consists in allowing destructive updates of variables that could be aliased arguments. We however keep track of these arguments and only call this function when we are sure the arguments are safe in the context of the call. 
The yields the definition $e_d$ of $f^d$ verifying the following properties:
\begin{itemize}
\item If $e = U\ucont{X\cl{[(}x \cl{) := } y \cl{]}}$ and $U'$ is the corresponding context in $e_d$ then
$$ e_d = U'\ucont{X\cl{[(}x \cl{) <- } y \cl{]}} \ \Longleftrightarrow \ Cv(U')(X) \cap Lv(U') = \emptyset $$
\item If $e = U\ucont{g^d\cl{(}x_1 \cl{,} ... \cl{,} x_n \cl{)}}$ and $U'$ is the corresponding context in $e_d$ then the condition for $e_d = U'\ucont{X\cl{[(}x \cl{) <- } y \cl{]}}$ is
$$ \text{All } Cv(U')(x_i) \text{ for } g_i^d \in BA(g^d) \text{ and } Lv(U') \text{ are pairwise disjoints.} $$
\end{itemize}
\item The first consists in forbidding the use of destructive updates which argument may be pointing to by arguments. This is equivalent to saying that all arguments of non destructive functions are live in all contexts (or just in the empty context).
This yields the new definition $e_{nd}$ of $f$ verifying the following properties:
\begin{itemize}
\item If $e = U\ucont{X\cl{[(}x \cl{) := } y \cl{]}}$ and $U'$ is the corresponding context in $e_{nd}$ then
$$ e_{nd} = U'\ucont{X\cl{[(}x \cl{) <- } y \cl{]}} \ \ \Longleftrightarrow \ \  Cv(U')(X) \cap \left( Lv(U') \cup \{f_1, ... , f_n \} \right) = \emptyset $$
\item If $e = U\ucont{g^d\cl{(}x_1 \cl{,} ... \cl{,} x_n \cl{)}}$ and $U'$ is the corresponding context in $e_{nd}$ then the condition for $e_d = U'\ucont{X\cl{[(}x \cl{) <- } y \cl{]}}$ is
$$ \text{All  } Cv(U)(x_i) \text{ for } g^d_i \in BA(g^d) \text{ and } Lv(U) \cup \{f_1, ... , f_n \} \text{ pairwise disjoints.}  $$
\end{itemize}
\end{itemize}
\begin{proposition}
For all non destructive version of a function $f$, $ BA(f) = \emptyset$.
\end{proposition}

\subsection{Proof of bisimulation}

We define the accessible cells, from a variable $X$ given a store $S$ as the set of all references (heap store entries) that can be accessed from the variable $X$.
$$ Ac(S)(X) := R \cap S^{\infty}(X)$$
We extend that definition of S to star variables and of $Ac$ to expressions and updates
\begin{eqnarray*}
S(X^*) := Ac(S)(X) \\
Ac(S)(e) &:=& Ac(S)( Av(e) ) \\
Ac(S)(U) &:=& Ac(S)( Lv(U) )
\end{eqnarray*}
It correspond to the only references already created in the heap store that can still be accessed in the context or expression. \\

The proof of correctness relies on three main invariants:
\begin{enumerate}
\item The function calls to $f$ or $f^d$ have the same evaluation. This means they can't be told apart by looking only at the value of the result. However they differ in the use of their arguments.
\item When the function call $f(x_i)$ is evaluated with a store $S$, the only references which value could be modified is $\bigcup_{f^{(*)}_i \in BA(f)} S\left(x^{(*)}_i\right)$.
\item The union above is always a pairwise disjoint union.
\end{enumerate}
These properties are obviously true before the analysis since $f = f^d$, $BA(f) = \emptyset$ for all function and no reference ever have its value modified.\\

The destructive and non destructive versions of a function $f$ are built from the original definition $e$ by replacing function calls (updates can be considered as a function call). To prove the correctness of this algorithm we need to prove that the three invariants described above are preserved between programs before and after a single replacement. \\

We consider the replacement of $g$ to $g^d$ in a function $f^d$ of body $e =  U\ucont{g^d\cl{(}x_i \cl{,} y_j \cl{,} z_k \cl{)}}$ with $x_i$ variables corresponding to the critical arguments $g^d_i \in BA(g^d)$, $y_j$ corresponding to arguments that are active in the body of $e$ and $z_k$ arguments that are not arrays or are not in either of the previous sets. \\

We have the following hypothesis
\begin{itemize}
\item[$(H1)$] All $Cv(U)(x_i)$ and $Lv(U)$ are pairwise disjoints (Analysis).
\item[$(H2)$] The evaluation of the call to $g^d$ with a store $S$ is the same than if $g$ was called.
\item[$(H3)$] The only references which value may be modified during the evaluation of the call with a store $S$ is the union $\bigcup_{f^{(*)}_i \in BA(f)} S\left(x^{(*)}_i\right)$.
\item[$(H4)$] $f$ will always be called in an evaluation context with a store $S$ such that the sets $S\left(f^{(*)}_i\right)$ are disjoint for all $f^{(*)}_i \in BA(f)$.
\end{itemize}
\begin{proposition}
For all store $S$ with which this function call is evaluated, the sets $S\left(x^{(*)}_i\right)$ are pairwise disjoint.
\end{proposition}
\begin{proof}
$(H1)$ and $(H4)$.
\end{proof}

\begin{proposition}
For all store $S$ with which the function call is evaluated, the sets $\bigcup S\left(x^{(*)}_i\right)$ and $Ac(S)(U)$ are disjoints.
\end{proposition}
\begin{proof}
$(H1)$ and $(H4)$.
\end{proof}

\begin{proposition}
When a call to $f^d$ is evaluated with a store $S$ the only references that may be modified in $S$ is $\bigcup_{f^{d,(*)}_i \in BA(f)} S\left(x^{(*)}_i\right)$
\end{proposition}
\begin{proof}
By definition of $BA(f)$, all the arguments that may point to references that could newly be modified are added to $BA(f)$.
\end{proof}

\begin{proposition}
The function calls to $f$ or $f^d$ have the same evaluation.
\end{proposition}
\begin{proof}
The only modification in the evaluation of a function call to the new $f^d$ is the function call to $g^d$. That function call has the same evaluation, $(H2)$, and the only references it may modify, $(H3)$ are never used afterward in the evaluation of the body of $f^d$, $(H1)$.
\end{proof}

This analysis would have worked as well for non destructive versions of functions and for the replacement of an update rather than a function call.



\begin{theorem}
If $<e_1, (s_1, h_1)> \ \longrightarrow \ <e_2, (s_2, h_2)>$ then $<e_1, (s_1, h'_1)> \ \longrightarrow \ <e_2, (s_2, h'_2)>$ where $h'_i = h_i|_{Lc(S_1)(e_1)}$.
\end{theorem}
\begin{proof}
It can easily be verified for every redex. When $a = U\ucont{b}$, we have $Lc(a) = Lc(U) \cup Lc(b)$ and the inductive step is proved .
\end{proof}








\newpage
\section{Conclusion}
\label{sec:Concl}

We have described the general architecture of the translator from PVS to the C language we implemented and integrated into PVS. We have provided a few examples of its execution on simple examples to illustrate its mechanisms.

We have described the update issue and various ways to deal with it. Both the use of a reference counting garbage collector and an analysis of the intermediate language were implemented.

We have defined the semantics of the intermediate language which allowed us to prove the correctness of the analysis that is performed on it to eliminate non destructive updates.

This tool allows to efficiently execute PVS code for debugging and testing purposes and to easily integrate C code into actual systems where the C and C++ are common development languages.



\subsection{Difficulties and successes}

This project was a great challenge and an opportunity for me to conduct my own autonomous research on a subject I chose. The development of the working translator was also the occasion for me to discover new tools, formal techniques and learn a lot about computer science in general.


\subsubsection*{Working with new languages and tools}

To be able to translate PVS, I had to fully understand not only the syntax and semantics of the PVS language but also the structure of the PVS API written in Common Lisp. This means I also had to learn Common Lisp which I decided then to use to write the translator mostly because it made the integration of the native PVS parser and typechecker easier. Finally I had to discover the C language which I only had a basic knowledge of.


\subsubsection*{Integrating the GMP library}
In PVS (and in other languages such as Common Lisp or Python), the \cl{integer} type represent the whole set $\Z$ of all relative numbers (and \cl{rational} also describes the whole set $\Q$).
To implement that in C, we need more than the finite types \cl{int}, \cl{long}, etc.

\begin{figure}[!ht]
\cl{norm(x:int, y:int):int = x*x + y*y}
\begin{lstlisting}
void norm(mpz_t result, mpz_t x, mpz_t y) {
  mpz_t aux1;
  mpz_init(aux1);
  mpz_mul(aux1, x, x);
  mpz_clear(x);
  mpz_t aux2;
  mpz_init(aux2);
  mpz_mul(aux2, y, y);
  mpz_clear(y);
  mpz_add(result, aux1, aux2);
  mpz_clear(aux1);
  mpz_clear(aux2);
}
\end{lstlisting}
\caption{Example of the GMP library use}
\label{fig:exGMP}
\end{figure}

The translator uses the GMP library which introduces the types \mpzt and \mpqt. These types are pointers (technically arrays) to structures and they had to be used with caution (allocation, freeing, ...).

For example (Figure~\ref{fig:exGMP}), a function returning a \mpzt should actually take a first \mpzt argument and set it to the return value. Its return type being \cl{void}.


\subsection{What's left to be done ?}

One of my biggest regret was not having the time to finish the translator and properly implement closures. Some work is already done in that direction though. It relies on a C structure to represent a closure:
\begin{lstlisting}
struct r_list_int {
   int (*body)(void* env, void* args);  // body is a function pointer
   void* env;                           // env contains the environment variables
   void* args;                          // args will contain the arguments
};
\end{lstlisting}


Since the translator's correctness itself has not be proven, there is no formal guarantee that the semantic will be preserved during the translation. In particular, even if some properties were proven on a certain PVS model, its translation to C could not verify these properties. This tool certainly does not allow the generation of high insurance code. The only way to do that would be to formally prove the correctness of the translator. The CompCert C compiler (\href{http://compcert.inria.fr}{http://compcert.inria.fr/compcert-C.html}), is an example of such a proven translator. \\


We can only translate a subset of PVS syntax.
What's missing ? \\

We can only translate a subset of PVS type system.
What's missing ?


\subsection{My stay at SRI}

Besides the conception and implementation of the PVS to C translator, my stay at SRI International was rich in interesting events. 

The first weeks of my stay were the occasion to discover PVS and Coq as I started working on a translator Coq to PVS. With Robin, we also wrote as an exercise a basic linear algebra library.

I discovered Lisp the hard way while discovering the middle- and back-end of the PVS API. Among other excerises, I decided to write a Common Lisp parser to help me understand the huge architecture of the PVS API code (classes definitions, inheritances and organization, function dependances, ...)

I also have had the chance to attend to the many interesting seminars SRI hosted every week. The "Crazy Ideas" seminar hosted every other week was a ...

The SRI also organized a Summer School to which we were allowed to attend and which was very interesting.

Shankar never hesitated to include us in many project

I've been included in the HACMS project which was very interesting.
With other:
Correcting translator PVS to SMT-LIB

Discovering PVS :
Translating Coq proofs to PVS
PVS library for basic linear algebra

Robin project, HACMS \\
Contest week-end 14-15 June \\
Summer School \\
Parsing Lisp code -> generate HTML architecture file\\
Correcting translator PVS to SMT-LIB




\printbibliography

\appendix

\newpage
\section{PVS syntax and CLOS representation}

\begin{figure}[h]
\input{includes/PVS-expr}
\caption{Syntax of the PVS subset of the translator}
\label{fig:PVSsyntax}
\end{figure}

\begin{figure}[!ht]
\input{includes/PVS-CLOS}
\caption{(Partial) CLOS representation of PVS syntax}
\label{fig:PVS-CLOS}
\end{figure}

\newpage
\section{PVS type system and CLOS representation}

\begin{figure}[!ht]
\input{includes/PVS-type}
\caption{Fragment of the PVS type system}
\label{fig:PVS-types}
\end{figure}


\begin{figure}[!ht]
\input{includes/PVS-CLOS-type}
\caption{(Partial) CLOS representation of PVS types}
\label{fig:PVS-CLOS-types}
\end{figure}


\newpage
\section{Intermediate languages}

\begin{figure}[!ht]
\input{includes/aux-expr}
\caption{Syntax of the intermediate language}
\label{fig:aux-syntax}
\end{figure}

\newpage
\begin{figure}[!ht]
\input{includes/C-expr}
\caption{Syntax of the representation language. Every $Expr$ is typed.}
\label{fig:Csyntax}
\end{figure}



\newpage
\section{Rules}
\label{Rules}


\begin{figure}[!ht]
\begin{tabular}{|p{4.5cm}|p{6cm}|p{6.5cm}|}
\hline
             & \cl{A} \safe & \cl{A} not \safe \\ \hline
\cl{A} \mut  &
\begin{lstlisting}
A[k] = v;
\end{lstlisting}
Replace every occurrence of the variable \cl{B} by the variable \cl{A} & \begin{lstlisting}
B = GC_malloc(...);
for(i ...)
  B[i] = A[i];
B[k] = v;
\end{lstlisting} \\ \hline
\cl{A} \nmut & \begin{lstlisting}
if (GC_count(A) == 1) {
  B = A;
} else {
  B = GC_malloc(...);
  for(i ...)
    B[i] = A[i];
}
B[k] = v;
\end{lstlisting} & \begin{lstlisting}
B = GC_malloc(...);
for(i ...)
  B[i] = A[i];
B[k] = v;
\end{lstlisting} \\ \hline
\end{tabular}
\caption{Rules for \cl{set(B, A[(i) := v])}}
\end{figure}



\begin{figure}[!ht]
\begin{tabular}{|p{4.5cm}|p{6cm}|p{6.5cm}|}
\hline
             & \cl{A} \safe & \cl{A} not \safe \\ \hline
\cl{A} \mut  & Replace every occurrence of the variable \cl{B} by the variable \cl{A} & \begin{lstlisting}
B = GC_malloc(...);
for(i ...) {
  B[i] = A[i]
}
\end{lstlisting} \\ \hline
\cl{A} \nmut & Replace every occurrence of the variable \cl{B} by the variable \cl{A} & \begin{lstlisting}
B = GC( A );
\end{lstlisting}
If \cl{B} is flagged \dupl then \cl{A} must be too.
\\ \hline
\end{tabular}
\caption{Rules for \cl{set(B, A)}}
\end{figure}



\begin{figure}[!ht]
\begin{tabular}{|p{4.5cm}|p{6cm}|p{6.5cm}|}
\hline
             & \cl{A} \safe & \cl{A} not \safe \\ \hline
\cl{A} \bang  &
\begin{lstlisting}
f_d(A)
\end{lstlisting} & \begin{lstlisting}
f(A)
\end{lstlisting} \\ \hline
\cl{A} not \bang & \begin{lstlisting}
f(A)
\end{lstlisting} & \begin{lstlisting}
f(A)
\end{lstlisting} \\ \hline
\end{tabular}
\caption{Rules for \cl{f(A)} with \cl{A} flagged \bang in the destructive version}
\end{figure}


\newpage

\section{Examples}
Here are a few simple example to get an idea of the optimization that occur on the intermediate language. Following is a complete example of a program generating an array of pseudo random numbers and sorting it with the insertion sort algorithm.

\begin{figure}[!ht]
\begin{tabular}{|p{5.2cm}|p{5.8cm}|p{6cm}|}
\hline
\begin{center}
PVS code
\end{center} &
\begin{center}
Intermediate language code\\
(before analysis - with types)
\end{center} &
\begin{center}
C code generated\\
(after analysis)
\end{center} \\ \hline

\begin{lstlisting}
f(A:Arr):Arr = A
\end{lstlisting} &
\cl{f: ( int* A ) -> int*} \newline
\cl{A} &
\begin{lstlisting}
int* f(int* A) {
  return A;
}
\end{lstlisting} \\ \hline

\begin{lstlisting}
f(A:Arr):Arr =
  let B = A in B
\end{lstlisting} &
\cl{f: ( int* A ) -> int*} \newline
\cl{set(B, A);} \newline
\cl{B} &
\begin{lstlisting}
int* f(int* A) {
  return A;
}
\end{lstlisting} \\ \hline

\begin{lstlisting}
f(A:Arr):Cint =
 let B = A in
  A(0) + B(0)
\end{lstlisting} &
\cl{f: ( int* A ) -> int} \newline
\cl{set(B, A);} \newline
\cl{+( A(0), B(0) )} &
\begin{lstlisting}
int* f(int* A) {
  int* B = (int*) GC( A );
  int result = A[0] + B[0];
  GC_free(B);
  GC_free(A);
  return result;
}
\end{lstlisting} \\ \hline

\begin{lstlisting}
f(A:Arr):Arr =
  let B = A in
    A WITH [(0) := B(0)]
\end{lstlisting} &
\cl{fd: ( int* A ) -> int} \newline
\cl{set(B, A);} \newline
\cl{set(L, 0);} \newline
\cl{set(R, B(0) );} \newline
\cl{A[(L) := R]} &
\begin{lstlisting}
int* f_d(int* A) {
  int* B = GC_malloc(...);
  for(i ...)
     B[i] = A[i];
  int L = 0;
  int R = B[0];
  GC_free(B);
  int* result = GC( A );
  GC_free(A);
  result[L] = R;
  return result;
}
\end{lstlisting} \\ \hline
\end{tabular}
\caption{Examples of setting variables}
\end{figure}


\begin{figure}[!ht]
\begin{tabular}{|p{5.5cm}|p{5.5cm}|p{6cm}|}
\hline
\begin{center}
PVS code
\end{center} &
\begin{center}
Intermediate language code
\end{center} &
\begin{center}
C code generated
\end{center} \\ \hline

\begin{lstlisting}
f(A:Arr):Arr =
  A WITH [(0) := 0]
\end{lstlisting} &
\ \newline
\cl{f: ( int* A ) -> int*} \newline
\cl{set(L, 0);} \newline
\cl{set(R, 0);} \newline
\cl{A[(L) := R]} \newline
\ \newline
(after analysis) \newline
\ \newline
\cl{fd: ( int* A ) -> int*} \newline
\cl{set(L, 0);} \newline
\cl{set(R, 0);} \newline
\cl{A[(L) <- R]}
 &
\begin{lstlisting}
int* f(int* A) {
  int L = 0, R = 0;
  int* result;
  if( GC_count(A) == 1 ) {
    result = GC( A );
  } else {
    result = GC_alloc(...);
    for(i ...)
      result[i] = A[i];
  }
  result[L] = R;
  GC_free( A );
  return result;
}

int* f_d(int* A) {
  int L = 0, R = 0;
  A[L] = R;
  return A;
}
\end{lstlisting} \\ \hline

\begin{lstlisting}
f(A:Arr):Arr =
 let B = A WITH[(0):=0]
 in A WITH[(0) := B(0)]
\end{lstlisting} &
\ \newline
\cl{f: ( int* A ) -> int*} \newline
\cl{set(L1, 0);} \newline
\cl{set(R1, 0);} \newline
\cl{set(B, A[(L1) := R1] );} \newline
\cl{set(L2, 0);} \newline
\cl{set(R2, B(0));} \newline
\cl{A[(L2) := R2] );} \newline
\ \newline
(after analysis) \newline
\ \newline
\cl{fd: ( int* A ) -> int*} \newline
\cl{set(L1, 0);} \newline
\cl{set(R1, 0);} \newline
\cl{set(B, A[(L1) := R1] );} \newline
\cl{set(L2, 0);} \newline
\cl{set(R2, B(0));} \newline
\cl{A[(L2) <- R2] );}
&
\begin{lstlisting}
int* f(int* A) {
  int R1 = 0, L1 = 0;
  B = GC_alloc(...);
  for(i ...)
    B[i] = A[i];
  B[L1] = R1;
  int R2 = 0, L2 = B[0];
  result = GC_alloc(...);
  for(i ...)
    result[i] = A[i];
  result[L2] = R2;
  GC_free(A);
  GC_free(B);
  return result;
}

int* f_d(int* A) {
  int R1 = 0, L1 = 0;
  B = GC_alloc(...);
  for(i ...)
    B[i] = A[i];
  B[L1] = R1;
  int R2 = 0, L2 = B[0];
  A[L2] = R2;
  GC_free(B);
  return A;
}
\end{lstlisting} \\ \hline
\end{tabular}
\caption{Examples of copying variables}
\end{figure}



\newpage
\begin{figure}
\begin{lstlisting}[numbers=left,language=TeX]
benchmark : THEORY
BEGIN

% We use the Lehmer random number generator
% with the following parameters

% n      = 59557   big prime number picked from
%                  http://primes.utm.edu/lists/small/10000.txt
% length = 1000
% g      = 12345
% X_0    = 9876

  SIZE: int = 1000
  
  Val  : TYPE+ = subrange(0, 59557)
  Ind  : TYPE+ = below(SIZE)
  Arr  : TYPE+ = [ Ind -> Val ]
  
  A : VAR Arr
  i : VAR Ind
  v : VAR Val
  
  init(A, i, v): RECURSIVE Arr =
    let B = A with [(i) := v] in
      if i >= SIZE-1 then B	
      else init(B, i+1, rem(59557)(12345 * v) ) endif
  MEASURE SIZE - 1 - i
  
  J :Arr = lambda(k:Ind): SIZE - 1 - k
  Z :Arr = lambda(x:Ind) : 0
  T :Arr = init(Z, 0, 9876)
  
  
  insert(A, v, i): RECURSIVE Arr =
    IF (i = 0 OR v >= A(i - 1))
    THEN A WITH [(i) := v]
    ELSE insert(A WITH [(i) := A(i - 1)], v, i - 1)
    ENDIF
    MEASURE i

  insort_rec(A, (n:upto(SIZE)) ): RECURSIVE Arr =
    IF n < SIZE THEN
      let An = A(n) in
        insort_rec( insert(A, An, n), n + 1 )
    ELSE A ENDIF
    MEASURE SIZE - n

  insort(A): Arr = insort_rec(A, 0)
  
  tsort: Val = insort(T)(0)
  jsort: Val = insort(J)(0)
  
END benchmark
\end{lstlisting}
\caption{Full PVS example - PVS theory}
\label{fig:PVSbenchmark}
\end{figure}


\begin{figure}
\begin{lstlisting}
#define SIZE 1000;
#define SIZE_1 SIZE-1;

unsigned long int* init(unsigned long int* A, int i, unsigned long int v) {
  A[i] = v;
  if ((i >= SIZE_1))
    return A;
  else
    return init( A , (i + 1) , ((12345 * v) % 59557) );
}

unsigned long int J(int k) {
  return (unsigned long int) (SIZE_1 - k);  }

unsigned long int Z(int x) {
  return (unsigned long int) 0;  }

unsigned long int* T() {
  unsigned long int* aux = GC_malloc(SIZE, sizeof(unsigned long int) );
  int i;
  for(i = 0; i < SIZE; i++)
    aux[i] = Z( i );
  return init( aux , 0 , (unsigned long int) 9876 );
}

unsigned long int* insert(unsigned long int* A, unsigned long int v, int i) {
  if (((i == 0) || (v >= A[(i - 1)]))) {
    A[i] = v;
    return A;
  } else {
    unsigned long int res = A[(i - 1)];
    A[i] = res;
    return insert( A , v , (i - 1) );
  }
}

unsigned long int* insort_rec(unsigned long int* A, int n) {
  if ((n < SIZE)) {
    unsigned long int An = A[n];
    return insort_rec( insert( A , An , n ) , (n + 1) );
  } else  return A;
}

unsigned long int* insort(unsigned long int* A) { return insort_rec( A , 0 ); }

unsigned long int tsort() { return insort( T() )[0]; }

unsigned long int jsort() {
  unsigned long int* aux;
  aux = GC_malloc(SIZE, sizeof(unsigned long int) );
  int i;
  for(i = 0; i < SIZE; i++)
    aux[i] = J( i );
  return insort( aux )[0];
}
\end{lstlisting}
\caption{Full PVS example - C translation}
\label{fig:Cbenchmark}
\end{figure}




\end{document}
